{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 02 - Event Study Analysis\n",
    "\n",
    "This notebook demonstrates **Event Study Analysis** - a standard finance technique to measure if a specific event caused an abnormal market reaction.\n",
    "\n",
    "---\n",
    "\n",
    "## What is an Event Study?\n",
    "\n",
    "Event studies are the **gold standard in finance** for answering: *\"Did this event affect the stock/market?\"*\n",
    "\n",
    "**Real-world applications:**\n",
    "- Did the Fed rate announcement move stocks?\n",
    "- Did the CEO departure hurt the company?\n",
    "- Did the sanctions affect oil prices?\n",
    "- Did the earnings beat expectations?\n",
    "\n",
    "**The key insight:** Markets are noisy - prices move every day. To isolate an event's effect, we need to compare *actual* returns to *expected* returns.\n",
    "\n",
    "---\n",
    "\n",
    "## The Methodology\n",
    "\n",
    "```\n",
    "         ESTIMATION WINDOW           GAP    EVENT WINDOW\n",
    "    |---------------------------|   |---|  |----------|\n",
    "    t-40                       t-6  t-2 t-1  t=0  t+1 ... t+5\n",
    "    \n",
    "    \"What's normal?\"                      \"What happened?\"\n",
    "```\n",
    "\n",
    "1. **Estimation Window** (t-40 to t-6): Calculate \"normal\" daily returns\n",
    "2. **Gap** (t-5 to t-2): Buffer to avoid event contamination\n",
    "3. **Event Window** (t-1 to t+5): Measure actual returns around the event\n",
    "4. **Abnormal Return** = Actual - Expected (for each day)\n",
    "5. **CAR** = Cumulative Abnormal Return (sum of all abnormal returns)\n",
    "6. **Statistical Test**: Is CAR significantly different from zero?\n",
    "\n",
    "---\n",
    "\n",
    "## Key Concepts You'll Learn\n",
    "\n",
    "| Concept | Description | Why It Matters |\n",
    "|---------|-------------|----------------|\n",
    "| **Abnormal Return (AR)** | Return beyond what's expected | Isolates event impact from normal noise |\n",
    "| **CAR** | Sum of ARs over event window | Total cumulative impact |\n",
    "| **t-statistic** | CAR / Standard Error | Measures \"how many SEs from zero\" |\n",
    "| **p-value** | Probability of seeing CAR by chance | <0.05 means statistically significant |\n",
    "| **Confidence Interval** | Range of plausible CAR values | 95% CI tells you uncertainty |\n",
    "\n",
    "---\n",
    "\n",
    "We'll compare our **learning version** (manual implementation) with the **production version** (using scipy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "# IMPORTS\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "#\n",
    "# Standard practice: Group imports by category\n",
    "#   1. Standard library (sys, pathlib, datetime)\n",
    "#   2. Third-party (pandas, numpy, matplotlib)\n",
    "#   3. Project-specific (src.analysis)\n",
    "#\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import date, timedelta\n",
    "\n",
    "# Add project root to Python path\n",
    "# This allows us to import from src/ even when running from notebooks/\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Matplotlib style\n",
    "# 'seaborn-v0_8-whitegrid' provides clean, professional plots\n",
    "# The grid helps with reading values off charts\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Understanding Event Studies\n",
    "\n",
    "### Why Not Just Look at Returns?\n",
    "\n",
    "You might think: *\"If oil dropped 3% on the day of a geopolitical event, the event caused the drop, right?\"*\n",
    "\n",
    "**Not necessarily.** Here's why:\n",
    "\n",
    "1. **Oil is volatile** - it might drop 3% on a random Tuesday\n",
    "2. **Multiple factors** - interest rates, inventory reports, demand forecasts all affect oil\n",
    "3. **Market anticipation** - traders might have priced in the event beforehand\n",
    "\n",
    "**The solution:** Compare the *actual* return to what we'd *expect* based on recent history.\n",
    "\n",
    "### The Timeline Visualization\n",
    "\n",
    "Let's visualize the event study timeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "# EVENT STUDY TIMELINE VISUALIZATION\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "#\n",
    "# This visualization shows the three critical periods:\n",
    "#\n",
    "# 1. ESTIMATION WINDOW (blue):\n",
    "#    - Used to calculate \"normal\" market behavior\n",
    "#    - Typically 30-250 trading days\n",
    "#    - We use the MEAN return as our \"expected\" return\n",
    "#    - We use the STANDARD DEVIATION for statistical tests\n",
    "#\n",
    "# 2. GAP PERIOD:\n",
    "#    - Buffer between estimation and event windows\n",
    "#    - Prevents event anticipation from contaminating \"normal\" estimates\n",
    "#    - Usually 2-5 days before the event\n",
    "#\n",
    "# 3. EVENT WINDOW (red):\n",
    "#    - The period we're actually studying\n",
    "#    - Includes days before (anticipation) and after (reaction)\n",
    "#    - Typically t-1 to t+5 or t-2 to t+10\n",
    "#\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 4))\n",
    "\n",
    "# Timeline base\n",
    "days = list(range(-40, 11))\n",
    "ax.axhline(y=0, color='black', linewidth=2)\n",
    "\n",
    "# Estimation window (where we learn \"normal\" behavior)\n",
    "ax.axvspan(-40, -6, alpha=0.3, color='blue', label='Estimation Window')\n",
    "ax.text(-23, 0.3, 'ESTIMATION WINDOW\\n(Calculate normal returns)\\n\\nμ = mean return\\nσ = std deviation', \n",
    "        ha='center', fontsize=10)\n",
    "\n",
    "# Event window (where we measure impact)\n",
    "ax.axvspan(-1, 5, alpha=0.3, color='red', label='Event Window')\n",
    "ax.text(2, 0.3, 'EVENT\\nWINDOW\\n\\nMeasure\\nactual returns', ha='center', fontsize=10)\n",
    "\n",
    "# Event day marker\n",
    "ax.axvline(x=0, color='green', linewidth=3, label='Event Day (t=0)')\n",
    "ax.annotate('EVENT!', xy=(0, 0), xytext=(0, -0.5), fontsize=12, ha='center',\n",
    "            arrowprops=dict(arrowstyle='->', color='green'))\n",
    "\n",
    "# Gap annotation\n",
    "ax.annotate('Gap', xy=(-3.5, 0.1), fontsize=9, ha='center', color='gray')\n",
    "\n",
    "ax.set_xlim(-45, 15)\n",
    "ax.set_ylim(-0.8, 0.8)\n",
    "ax.set_xlabel('Days Relative to Event (t=0 is event day)')\n",
    "ax.set_yticks([])\n",
    "ax.set_title('Event Study Timeline: Separating \"Normal\" from \"Event Impact\"')\n",
    "ax.legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey insight: The ESTIMATION WINDOW must be BEFORE the event,\")\n",
    "print(\"so we're measuring 'normal' behavior unaffected by the event!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 2. Learning Version: Step-by-Step\n",
    "\n",
    "Our **learning version** implements everything from scratch so you can see exactly how it works.\n",
    "\n",
    "### The Algorithm\n",
    "\n",
    "```python\n",
    "# Pseudocode for event study\n",
    "\n",
    "# Step 1: Estimate \"normal\" returns\n",
    "expected_return = mean(estimation_window_returns)\n",
    "std_dev = std(estimation_window_returns)\n",
    "\n",
    "# Step 2: Calculate abnormal returns for each day in event window\n",
    "for day in event_window:\n",
    "    AR[day] = actual_return[day] - expected_return\n",
    "\n",
    "# Step 3: Sum up the abnormal returns\n",
    "CAR = sum(AR)  # Cumulative Abnormal Return\n",
    "\n",
    "# Step 4: Test if CAR is statistically significant\n",
    "SE = std_dev * sqrt(len(event_window))  # Standard Error of CAR\n",
    "t_stat = CAR / SE\n",
    "p_value = 2 * (1 - t_distribution.cdf(abs(t_stat)))\n",
    "\n",
    "# Significant if p < 0.05\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "# LEARNING VERSION: EventStudy CLASS\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "#\n",
    "# This is our EDUCATIONAL implementation that shows all the math.\n",
    "#\n",
    "# Key parameters:\n",
    "#   - estimation_window: Days to calculate \"normal\" (30 is common)\n",
    "#   - event_window_before: Days before event to include (captures anticipation)\n",
    "#   - event_window_after: Days after event to include (captures full reaction)\n",
    "#   - significance_level: Alpha for hypothesis test (0.05 = 95% confidence)\n",
    "#\n",
    "# Academic standards:\n",
    "#   - estimation_window: 120-250 days for stocks, 30-60 for commodities\n",
    "#   - event_window: Depends on event type (earnings: 3 days, M&A: 20+ days)\n",
    "#\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "from src.analysis.event_study import EventStudy, EventStudyResult, explain_result\n",
    "\n",
    "# Create analyzer with explicit parameters\n",
    "study = EventStudy(\n",
    "    estimation_window=30,     # 30 trading days to calculate \"normal\" returns\n",
    "    event_window_before=1,    # Include 1 day before (might show anticipation)\n",
    "    event_window_after=5,     # Include 5 days after (capture full reaction)\n",
    "    significance_level=0.05,  # Standard 95% confidence level\n",
    ")\n",
    "\n",
    "print(\"Event Study Configuration\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"  Estimation window: {study.estimation_window} trading days\")\n",
    "print(f\"  Event window: [{-study.event_window_before}, +{study.event_window_after}] days\")\n",
    "print(f\"  Total event window days: {study.event_window_before + study.event_window_after + 1}\")\n",
    "print(f\"  Significance level (α): {study.significance_level}\")\n",
    "print(f\"  Confidence level: {(1 - study.significance_level) * 100:.0f}%\")\n",
    "print()\n",
    "print(\"Interpretation:\")\n",
    "print(f\"  - We'll use {study.estimation_window} days of data to establish 'normal'\")\n",
    "print(f\"  - We'll measure returns from day {-study.event_window_before} to day +{study.event_window_after}\")\n",
    "print(f\"  - If p-value < {study.significance_level}, we conclude the event had a real effect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "# RUNNING AN EVENT STUDY\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "#\n",
    "# We pick a date from about 2 weeks ago to ensure:\n",
    "#   1. We have the required estimation window data (30 days before)\n",
    "#   2. We have the full event window data (5 days after)\n",
    "#\n",
    "# The study.analyze_event() method:\n",
    "#   1. Fetches market data from the database\n",
    "#   2. Calculates expected returns from estimation window\n",
    "#   3. Computes abnormal returns for each day in event window\n",
    "#   4. Sums them into CAR (Cumulative Abnormal Return)\n",
    "#   5. Performs t-test for statistical significance\n",
    "#\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "# Choose a date with enough data on both sides\n",
    "event_date = date.today() - timedelta(days=14)\n",
    "symbol = \"CL=F\"  # Crude Oil Futures\n",
    "\n",
    "print(f\"Event Study: {symbol} on {event_date}\")\n",
    "print(\"=\" * 50)\n",
    "print()\n",
    "print(\"Data requirements:\")\n",
    "print(f\"  - Need data from: {event_date - timedelta(days=45)} (estimation start)\")\n",
    "print(f\"  - Through: {event_date + timedelta(days=7)} (event window end)\")\n",
    "print()\n",
    "\n",
    "# Run the event study\n",
    "result = study.analyze_event(\n",
    "    event_id=1,           # Just an identifier\n",
    "    symbol=symbol,        # Which market to analyze\n",
    "    event_date=event_date # The date of the \"event\"\n",
    ")\n",
    "\n",
    "if result:\n",
    "    # The explain_result function provides a human-readable summary\n",
    "    print(explain_result(result))\n",
    "else:\n",
    "    print(\"No result returned.\")\n",
    "    print()\n",
    "    print(\"Troubleshooting:\")\n",
    "    print(\"  1. Make sure you've run the data ingestion scripts\")\n",
    "    print(\"  2. Verify the database has data for this symbol and date range\")\n",
    "    print(\"  3. Try: python scripts/ingest_market_data.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "# VISUALIZING ABNORMAL RETURNS\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "#\n",
    "# Two views of the same data:\n",
    "#\n",
    "# LEFT PLOT - Daily Abnormal Returns:\n",
    "#   - Each bar shows AR for that day\n",
    "#   - Green = positive abnormal return (better than expected)\n",
    "#   - Red = negative abnormal return (worse than expected)\n",
    "#   - Day 0 (blue dashed line) is the event day\n",
    "#\n",
    "# RIGHT PLOT - Cumulative Abnormal Return (CAR):\n",
    "#   - Shows the running total of ARs\n",
    "#   - The FINAL value is what we test for significance\n",
    "#   - Shape tells you about timing:\n",
    "#     - Jump ON day 0 → immediate reaction\n",
    "#     - Gradual slope → delayed/prolonged reaction\n",
    "#     - Jump BEFORE day 0 → information leaked early\n",
    "#\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "if result:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Create day labels relative to event\n",
    "    days = list(range(-study.event_window_before, study.event_window_after + 1))\n",
    "    abnormal_returns = result.abnormal_returns[:len(days)]\n",
    "    \n",
    "    # ─── LEFT PLOT: Daily Abnormal Returns ───\n",
    "    colors = ['green' if r > 0 else 'red' for r in abnormal_returns]\n",
    "    \n",
    "    axes[0].bar(\n",
    "        days[:len(abnormal_returns)], \n",
    "        [r * 100 for r in abnormal_returns],  # Convert to percentage\n",
    "        color=colors, \n",
    "        alpha=0.7, \n",
    "        edgecolor='black'\n",
    "    )\n",
    "    axes[0].axhline(y=0, color='black', linestyle='-')\n",
    "    axes[0].axvline(x=0, color='blue', linestyle='--', linewidth=2, label='Event Day')\n",
    "    axes[0].set_xlabel('Days Relative to Event')\n",
    "    axes[0].set_ylabel('Abnormal Return (%)')\n",
    "    axes[0].set_title(f'Daily Abnormal Returns: {symbol}\\n(Actual - Expected)')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, (day, ar) in enumerate(zip(days[:len(abnormal_returns)], abnormal_returns)):\n",
    "        if abs(ar) > 0.005:  # Only label if > 0.5%\n",
    "            axes[0].annotate(f'{ar*100:.1f}%', \n",
    "                           xy=(day, ar*100), \n",
    "                           ha='center', \n",
    "                           va='bottom' if ar > 0 else 'top',\n",
    "                           fontsize=8)\n",
    "    \n",
    "    # ─── RIGHT PLOT: Cumulative Abnormal Return ───\n",
    "    car_cumulative = np.cumsum(abnormal_returns) * 100\n",
    "    \n",
    "    axes[1].plot(\n",
    "        days[:len(car_cumulative)], \n",
    "        car_cumulative, \n",
    "        marker='o', \n",
    "        linewidth=2, \n",
    "        markersize=8,\n",
    "        color='steelblue'\n",
    "    )\n",
    "    axes[1].axhline(y=0, color='black', linestyle='-')\n",
    "    axes[1].axvline(x=0, color='blue', linestyle='--', linewidth=2, label='Event Day')\n",
    "    \n",
    "    # Fill area to show magnitude\n",
    "    axes[1].fill_between(\n",
    "        days[:len(car_cumulative)], \n",
    "        0, \n",
    "        car_cumulative, \n",
    "        alpha=0.3,\n",
    "        color='green' if result.car > 0 else 'red'\n",
    "    )\n",
    "    \n",
    "    axes[1].set_xlabel('Days Relative to Event')\n",
    "    axes[1].set_ylabel('Cumulative Abnormal Return (%)')\n",
    "    axes[1].set_title(f'CAR Over Event Window\\nFinal CAR: {result.car*100:.2f}% (p={result.p_value:.3f})')\n",
    "    axes[1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Interpretation\n",
    "    print(\"\\nHow to read these charts:\")\n",
    "    print(\"─\" * 50)\n",
    "    print(\"LEFT: Each bar shows how much the return DEVIATED from expected\")\n",
    "    print(\"RIGHT: The cumulative sum - this is what we test for significance\")\n",
    "    if result.is_significant:\n",
    "        print(f\"\\n→ The {result.car*100:.2f}% CAR is STATISTICALLY SIGNIFICANT\")\n",
    "        print(f\"  There's only a {result.p_value*100:.1f}% chance this happened randomly\")\n",
    "    else:\n",
    "        print(f\"\\n→ The {result.car*100:.2f}% CAR is NOT statistically significant\")\n",
    "        print(f\"  This could easily be random noise (p={result.p_value:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## 3. Production Version: Using scipy\n",
    "\n",
    "The **production version** uses scipy for more robust statistical tests:\n",
    "\n",
    "| Feature | Learning Version | Production Version |\n",
    "|---------|-----------------|--------------------|\n",
    "| Statistical test | Basic t-test | scipy.stats.ttest_1samp |\n",
    "| Confidence interval | Not included | Computed automatically |\n",
    "| Non-parametric test | Not included | Wilcoxon signed-rank |\n",
    "| Code complexity | ~100 lines | ~50 lines |\n",
    "\n",
    "### Why Use Both?\n",
    "\n",
    "- **Learning version**: Understand the math, great for interviews\n",
    "- **Production version**: Reliable, tested, what you'd use at work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "# PRODUCTION VERSION: Quick Analysis\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "#\n",
    "# The run_quick_event_study() function is a convenience wrapper that:\n",
    "#   1. Creates a ProductionEventStudy with default parameters\n",
    "#   2. Runs the analysis\n",
    "#   3. Returns a formatted summary string\n",
    "#\n",
    "# This is the \"just give me the answer\" approach - perfect for quick checks.\n",
    "#\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "from src.analysis.production_event_study import ProductionEventStudy, run_quick_event_study\n",
    "\n",
    "# Quick one-liner for fast analysis\n",
    "summary = run_quick_event_study(symbol, event_date)\n",
    "\n",
    "if summary:\n",
    "    print(\"Production Version - Quick Summary\")\n",
    "    print(\"=\" * 50)\n",
    "    print(summary)\n",
    "else:\n",
    "    print(\"No result - insufficient data\")\n",
    "    print(\"Ensure the database is populated with market data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "# PRODUCTION VERSION: Full Details\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "#\n",
    "# For more control, instantiate ProductionEventStudy directly.\n",
    "#\n",
    "# Additional features over learning version:\n",
    "#\n",
    "# 1. CONFIDENCE INTERVAL (ci_lower, ci_upper):\n",
    "#    - 95% CI tells you the range of plausible CAR values\n",
    "#    - If CI doesn't include 0, the effect is significant\n",
    "#\n",
    "# 2. WILCOXON SIGNED-RANK TEST (wilcoxon_p):\n",
    "#    - Non-parametric alternative to t-test\n",
    "#    - Doesn't assume returns are normally distributed\n",
    "#    - More robust for small samples or fat-tailed returns\n",
    "#\n",
    "# Interview tip: Mentioning \"I'd also run a Wilcoxon test because\n",
    "# returns have fat tails\" shows statistical sophistication!\n",
    "#\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "prod_study = ProductionEventStudy()\n",
    "prod_result = prod_study.analyze_event(event_id=1, symbol=symbol, event_date=event_date)\n",
    "\n",
    "if prod_result:\n",
    "    print(\"Production Version - Full Results\")\n",
    "    print(\"=\" * 50)\n",
    "    print()\n",
    "    print(\"Core Metrics:\")\n",
    "    print(f\"  CAR: {prod_result.car*100:.4f}%\")\n",
    "    print(f\"  t-statistic: {prod_result.t_statistic:.4f}\")\n",
    "    print(f\"  p-value: {prod_result.p_value:.4f}\")\n",
    "    print()\n",
    "    print(\"Confidence Interval:\")\n",
    "    print(f\"  95% CI: [{prod_result.ci_lower*100:.4f}%, {prod_result.ci_upper*100:.4f}%]\")\n",
    "    ci_includes_zero = prod_result.ci_lower <= 0 <= prod_result.ci_upper\n",
    "    print(f\"  CI includes zero: {ci_includes_zero} {'→ NOT significant' if ci_includes_zero else '→ SIGNIFICANT'}\")\n",
    "    print()\n",
    "    print(\"Statistical Significance:\")\n",
    "    print(f\"  Is significant (α=0.05): {prod_result.is_significant}\")\n",
    "    \n",
    "    if prod_result.wilcoxon_p:\n",
    "        print()\n",
    "        print(\"Non-parametric Test:\")\n",
    "        print(f\"  Wilcoxon signed-rank p-value: {prod_result.wilcoxon_p:.4f}\")\n",
    "        print(\"  (Doesn't assume normal distribution - more robust for financial returns)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 4. Analyzing Multiple Events\n",
    "\n",
    "Real-world event studies often analyze **multiple events** simultaneously:\n",
    "\n",
    "- Compare how different markets responded to the same event\n",
    "- Compare how the same market responded to different events\n",
    "- Build up statistical power by aggregating many events\n",
    "\n",
    "### Cross-Market Comparison\n",
    "\n",
    "Let's see how different markets responded to our event date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "# MULTI-MARKET COMPARISON\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "#\n",
    "# We analyze the same \"event\" across multiple markets:\n",
    "#\n",
    "# - CL=F: Crude Oil Futures (sensitive to geopolitical events)\n",
    "# - GC=F: Gold Futures (safe haven asset)\n",
    "# - SPY: S&P 500 ETF (broad US equity market)\n",
    "# - ^VIX: Volatility Index (fear gauge)\n",
    "#\n",
    "# Expectations for a NEGATIVE geopolitical event:\n",
    "# - Oil: ↑ (supply concerns) or ↓ (demand fears)\n",
    "# - Gold: ↑ (flight to safety)\n",
    "# - SPY: ↓ (risk-off sentiment)\n",
    "# - VIX: ↑ (increased fear/uncertainty)\n",
    "#\n",
    "# Note: VIX moves INVERSELY to market sentiment!\n",
    "#\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "symbols_to_analyze = ['CL=F', 'GC=F', 'SPY', '^VIX']\n",
    "results_list = []\n",
    "\n",
    "print(\"Analyzing multiple markets...\")\n",
    "print(\"─\" * 50)\n",
    "\n",
    "for sym in symbols_to_analyze:\n",
    "    result = prod_study.analyze_event(event_id=0, symbol=sym, event_date=event_date)\n",
    "    if result:\n",
    "        results_list.append({\n",
    "            'symbol': sym,\n",
    "            'date': event_date,\n",
    "            'car_pct': result.car * 100,\n",
    "            't_stat': result.t_statistic,\n",
    "            'p_value': result.p_value,\n",
    "            'significant': result.is_significant,\n",
    "        })\n",
    "        status = \"✓ SIGNIFICANT\" if result.is_significant else \"  not significant\"\n",
    "        print(f\"  {sym}: CAR = {result.car*100:+.2f}% (p={result.p_value:.3f}) {status}\")\n",
    "    else:\n",
    "        print(f\"  {sym}: No data available\")\n",
    "\n",
    "# Display as DataFrame\n",
    "if results_list:\n",
    "    print()\n",
    "    results_df = pd.DataFrame(results_list)\n",
    "    print(\"\\nEvent Study Results Across Markets\")\n",
    "    print(\"=\" * 60)\n",
    "    display(results_df.style.format({\n",
    "        'car_pct': '{:+.2f}%',\n",
    "        't_stat': '{:.3f}',\n",
    "        'p_value': '{:.4f}',\n",
    "    }))\n",
    "else:\n",
    "    print(\"\\nNo results - ensure data is ingested for these symbols\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "# VISUALIZATION: CAR COMPARISON ACROSS MARKETS\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "#\n",
    "# Visual encoding:\n",
    "#   - Bar HEIGHT = CAR magnitude\n",
    "#   - Bar COLOR = Direction (green = positive, red = negative)\n",
    "#   - Bar OPACITY = Statistical significance (solid = significant, faded = not)\n",
    "#\n",
    "# This visualization immediately tells you:\n",
    "#   1. Which markets were most affected\n",
    "#   2. Direction of the effect\n",
    "#   3. Which effects are statistically meaningful\n",
    "#\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "if results_list:\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    # Determine colors based on CAR direction\n",
    "    colors = ['green' if r['car_pct'] > 0 else 'red' for r in results_list]\n",
    "    # Determine opacity based on significance\n",
    "    alphas = [1.0 if r['significant'] else 0.4 for r in results_list]\n",
    "    \n",
    "    # Create bars\n",
    "    bars = ax.bar(\n",
    "        [r['symbol'] for r in results_list],\n",
    "        [r['car_pct'] for r in results_list],\n",
    "        color=colors,\n",
    "        edgecolor='black',\n",
    "    )\n",
    "    \n",
    "    # Apply alpha (opacity) for significance\n",
    "    for bar, alpha in zip(bars, alphas):\n",
    "        bar.set_alpha(alpha)\n",
    "    \n",
    "    # Reference line at zero\n",
    "    ax.axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, r in zip(bars, results_list):\n",
    "        height = bar.get_height()\n",
    "        va = 'bottom' if height > 0 else 'top'\n",
    "        offset = 0.1 if height > 0 else -0.1\n",
    "        sig_marker = '*' if r['significant'] else ''\n",
    "        ax.annotate(f\"{height:+.1f}%{sig_marker}\",\n",
    "                   xy=(bar.get_x() + bar.get_width()/2, height + offset),\n",
    "                   ha='center', va=va, fontsize=11, fontweight='bold')\n",
    "    \n",
    "    ax.set_xlabel('Market', fontsize=12)\n",
    "    ax.set_ylabel('Cumulative Abnormal Return (%)', fontsize=12)\n",
    "    ax.set_title(f'Event Impact Across Markets ({event_date})\\n(Faded = Not Statistically Significant, * = Significant)',\n",
    "                fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nInterpretation Guide:\")\n",
    "    print(\"─\" * 50)\n",
    "    print(\"• Solid bars: Statistically significant (p < 0.05)\")\n",
    "    print(\"• Faded bars: Not significant (could be random noise)\")\n",
    "    print(\"• Only draw conclusions from SOLID bars!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## 5. The Math Behind Event Studies\n",
    "\n",
    "Let's walk through the calculations **step by step** so you understand exactly what's happening.\n",
    "\n",
    "### The Four Steps\n",
    "\n",
    "1. **Estimate normal returns** from the estimation window\n",
    "2. **Calculate abnormal returns** for each event day\n",
    "3. **Sum into CAR** (Cumulative Abnormal Return)\n",
    "4. **Test significance** using a t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "# STEP 0: GET RAW DATA\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "#\n",
    "# First, we need to fetch the raw return data and split it into:\n",
    "#   - Estimation window: For calculating \"normal\" returns\n",
    "#   - Event window: For measuring the event's impact\n",
    "#\n",
    "# We use log returns because they're:\n",
    "#   - Additive across time (daily log returns sum to period return)\n",
    "#   - More normally distributed than simple returns\n",
    "#   - Standard in academic finance\n",
    "#\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "from src.db.queries import get_market_data\n",
    "from src.db.connection import get_session\n",
    "\n",
    "# Define our windows\n",
    "estimation_start = event_date - timedelta(days=45)  # Start of estimation\n",
    "estimation_end = event_date - timedelta(days=2)     # End of estimation (gap before event)\n",
    "event_start = event_date - timedelta(days=1)        # Event window start\n",
    "event_end = event_date + timedelta(days=5)          # Event window end\n",
    "\n",
    "print(\"Data Windows\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Estimation window: {estimation_start} to {estimation_end}\")\n",
    "print(f\"Event window:      {event_start} to {event_end}\")\n",
    "print()\n",
    "\n",
    "with get_session() as session:\n",
    "    data = get_market_data(session, 'CL=F', estimation_start, event_end)\n",
    "    \n",
    "    if data:\n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame([\n",
    "            {'date': d.date, 'return': d.log_return}\n",
    "            for d in data\n",
    "        ]).dropna()\n",
    "        \n",
    "        print(f\"Total data points loaded: {len(df)}\")\n",
    "        \n",
    "        # Split into windows\n",
    "        estimation_df = df[(df['date'] >= estimation_start) & (df['date'] <= estimation_end)]\n",
    "        event_df = df[(df['date'] >= event_start) & (df['date'] <= event_end)]\n",
    "        \n",
    "        print(f\"Estimation window: {len(estimation_df)} trading days\")\n",
    "        print(f\"Event window: {len(event_df)} trading days\")\n",
    "    else:\n",
    "        print(\"No data available. Please run the ingestion scripts.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "# STEP 1: ESTIMATE NORMAL RETURNS\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "#\n",
    "# From the estimation window, we calculate:\n",
    "#   - μ (mean): The expected daily return\n",
    "#   - σ (std): The typical daily volatility\n",
    "#\n",
    "# These become our baseline for \"normal\" market behavior.\n",
    "#\n",
    "# Why the mean? \n",
    "#   - Simple and unbiased\n",
    "#   - Alternative: CAPM-adjusted returns (but needs market data)\n",
    "#   - For short windows, mean works well\n",
    "#\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "if 'estimation_df' in dir() and len(estimation_df) > 0:\n",
    "    expected_return = estimation_df['return'].mean()\n",
    "    std_dev = estimation_df['return'].std()\n",
    "    \n",
    "    print(\"STEP 1: Estimate Normal Returns\")\n",
    "    print(\"=\" * 50)\n",
    "    print()\n",
    "    print(\"From the estimation window, we calculate:\")\n",
    "    print()\n",
    "    print(f\"  Expected (mean) daily return: {expected_return*100:.4f}%\")\n",
    "    print(f\"  Standard deviation:           {std_dev*100:.4f}%\")\n",
    "    print()\n",
    "    print(\"Interpretation:\")\n",
    "    print(f\"  - On a 'normal' day, oil returns about {expected_return*100:.4f}%\")\n",
    "    print(f\"  - With typical daily swings of ±{std_dev*100:.2f}%\")\n",
    "    print(f\"  - A 2σ move (unusual) would be ±{2*std_dev*100:.2f}%\")\n",
    "else:\n",
    "    print(\"No estimation data available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "# STEP 2: CALCULATE ABNORMAL RETURNS\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "#\n",
    "# Abnormal Return (AR) = Actual Return - Expected Return\n",
    "#\n",
    "# This isolates the \"abnormal\" component of each day's return.\n",
    "#\n",
    "# Interpretation:\n",
    "#   AR > 0: Market did BETTER than expected (positive surprise)\n",
    "#   AR < 0: Market did WORSE than expected (negative surprise)\n",
    "#   AR ≈ 0: Market did about as expected (no abnormal behavior)\n",
    "#\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "if 'event_df' in dir() and len(event_df) > 0:\n",
    "    # Calculate abnormal returns\n",
    "    abnormal = event_df['return'] - expected_return\n",
    "    \n",
    "    print(\"STEP 2: Calculate Abnormal Returns\")\n",
    "    print(\"=\" * 50)\n",
    "    print()\n",
    "    print(\"Formula: AR = Actual Return - Expected Return\")\n",
    "    print()\n",
    "    print(f\"{'Day':<6} {'Date':<12} {'Actual':>10} {'Expected':>10} {'Abnormal':>10}\")\n",
    "    print(\"─\" * 50)\n",
    "    \n",
    "    for i, (_, row) in enumerate(event_df.iterrows()):\n",
    "        ar = row['return'] - expected_return\n",
    "        day_label = f\"t{i-1:+d}\" if i != 1 else \"t=0\"  # Adjust based on window\n",
    "        print(f\"{day_label:<6} {str(row['date']):<12} {row['return']*100:>9.4f}% {expected_return*100:>9.4f}% {ar*100:>9.4f}%\")\n",
    "    \n",
    "    print(\"─\" * 50)\n",
    "    print()\n",
    "    print(\"Interpretation:\")\n",
    "    max_ar = abnormal.max()\n",
    "    min_ar = abnormal.min()\n",
    "    print(f\"  - Largest positive abnormal return: {max_ar*100:+.4f}%\")\n",
    "    print(f\"  - Largest negative abnormal return: {min_ar*100:+.4f}%\")\n",
    "else:\n",
    "    print(\"No event window data available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "# STEP 3: CALCULATE CUMULATIVE ABNORMAL RETURN (CAR)\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "#\n",
    "# CAR = Sum of all abnormal returns in the event window\n",
    "#\n",
    "# This is the TOTAL abnormal impact of the event.\n",
    "#\n",
    "# Why sum instead of average?\n",
    "#   - Sum captures total impact over the window\n",
    "#   - If event has multi-day effect, we want to capture all of it\n",
    "#   - Average would dilute a one-day spike\n",
    "#\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "if 'abnormal' in dir():\n",
    "    car = abnormal.sum()\n",
    "    \n",
    "    print(\"STEP 3: Calculate Cumulative Abnormal Return (CAR)\")\n",
    "    print(\"=\" * 50)\n",
    "    print()\n",
    "    print(\"Formula: CAR = Σ AR (sum of all abnormal returns)\")\n",
    "    print()\n",
    "    print(\"Calculation:\")\n",
    "    ar_values = [f\"{ar*100:+.4f}%\" for ar in abnormal]\n",
    "    print(f\"  CAR = {' + '.join(ar_values)}\")\n",
    "    print(f\"  CAR = {car*100:+.4f}%\")\n",
    "    print()\n",
    "    print(\"Interpretation:\")\n",
    "    if car > 0:\n",
    "        print(f\"  - The market returned {car*100:.2f}% MORE than expected\")\n",
    "        print(f\"  - This is a POSITIVE abnormal return\")\n",
    "    else:\n",
    "        print(f\"  - The market returned {abs(car)*100:.2f}% LESS than expected\")\n",
    "        print(f\"  - This is a NEGATIVE abnormal return\")\n",
    "else:\n",
    "    print(\"No abnormal returns calculated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "# STEP 4: TEST STATISTICAL SIGNIFICANCE\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "#\n",
    "# The key question: Is the CAR significantly different from zero?\n",
    "#\n",
    "# We use a t-test:\n",
    "#   1. Calculate Standard Error of CAR: SE = σ × √n\n",
    "#      - σ = std dev from estimation window\n",
    "#      - n = number of days in event window\n",
    "#   2. Calculate t-statistic: t = CAR / SE\n",
    "#      - Measures \"how many standard errors is CAR from zero\"\n",
    "#   3. Calculate p-value from t-distribution\n",
    "#      - Probability of seeing this t-stat by chance\n",
    "#\n",
    "# Decision rule: If p < 0.05, reject null hypothesis (CAR = 0)\n",
    "#\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "if 'car' in dir() and 'std_dev' in dir():\n",
    "    from scipy import stats\n",
    "    \n",
    "    n_days = len(event_df)\n",
    "    \n",
    "    # Standard Error of CAR\n",
    "    # Why sqrt(n)? Because variance of sum = n × variance of individual\n",
    "    # So SE of sum = sqrt(n) × SE of individual = sqrt(n) × σ\n",
    "    se_car = std_dev * np.sqrt(n_days)\n",
    "    \n",
    "    # t-statistic\n",
    "    t_stat = car / se_car\n",
    "    \n",
    "    # p-value (two-tailed test)\n",
    "    # We use t-distribution with (estimation_window - 1) degrees of freedom\n",
    "    df = len(estimation_df) - 1\n",
    "    p_value = 2 * (1 - stats.t.cdf(abs(t_stat), df=df))\n",
    "    \n",
    "    print(\"STEP 4: Test Statistical Significance\")\n",
    "    print(\"=\" * 50)\n",
    "    print()\n",
    "    print(\"Hypothesis Test:\")\n",
    "    print(\"  H₀ (null): CAR = 0 (no abnormal return)\")\n",
    "    print(\"  H₁ (alt):  CAR ≠ 0 (significant abnormal return)\")\n",
    "    print()\n",
    "    print(\"Calculations:\")\n",
    "    print(f\"  Standard Error = σ × √n = {std_dev*100:.4f}% × √{n_days}\")\n",
    "    print(f\"                 = {se_car*100:.4f}%\")\n",
    "    print()\n",
    "    print(f\"  t-statistic = CAR / SE = {car*100:.4f}% / {se_car*100:.4f}%\")\n",
    "    print(f\"              = {t_stat:.4f}\")\n",
    "    print()\n",
    "    print(f\"  Degrees of freedom: {df}\")\n",
    "    print(f\"  p-value (two-tailed): {p_value:.4f}\")\n",
    "    print()\n",
    "    print(\"─\" * 50)\n",
    "    print(\"RESULT:\")\n",
    "    print(\"─\" * 50)\n",
    "    if p_value < 0.05:\n",
    "        print(f\"  ✓ STATISTICALLY SIGNIFICANT at 95% confidence!\")\n",
    "        print(f\"  - p-value ({p_value:.4f}) < 0.05\")\n",
    "        print(f\"  - We REJECT H₀: The CAR is significantly different from zero\")\n",
    "        print(f\"  - The event likely had a real effect on the market\")\n",
    "    else:\n",
    "        print(f\"  ✗ NOT statistically significant\")\n",
    "        print(f\"  - p-value ({p_value:.4f}) ≥ 0.05\")\n",
    "        print(f\"  - We FAIL TO REJECT H₀: Cannot conclude CAR differs from zero\")\n",
    "        print(f\"  - This could easily be random market noise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Event Study Analysis** answers: *\"Did this event move the market more than expected?\"*\n",
    "\n",
    "---\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "| Metric | Formula | Interpretation |\n",
    "|--------|---------|----------------|\n",
    "| **Expected Return** | μ = mean(estimation_window) | \"Normal\" daily return |\n",
    "| **Abnormal Return** | AR = Actual - Expected | Deviation from normal |\n",
    "| **CAR** | Σ AR | Total abnormal impact |\n",
    "| **Standard Error** | SE = σ × √n | Uncertainty in CAR |\n",
    "| **t-statistic** | t = CAR / SE | # of SEs from zero |\n",
    "| **p-value** | P(|t| > observed) | Probability by chance |\n",
    "\n",
    "---\n",
    "\n",
    "### Decision Framework\n",
    "\n",
    "```\n",
    "p < 0.05  →  Significant     →  Event likely had real effect\n",
    "p ≥ 0.05  →  Not significant →  Could be random noise\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Two Implementations\n",
    "\n",
    "| Version | Class | Use Case |\n",
    "|---------|-------|----------|\n",
    "| **Learning** | `EventStudy` | Understand the math, interviews |\n",
    "| **Production** | `ProductionEventStudy` | Real work, adds CI & Wilcoxon |\n",
    "\n",
    "---\n",
    "\n",
    "### Common Pitfalls\n",
    "\n",
    "1. **Confounding events**: Another event happened in your window\n",
    "2. **Data snooping**: Picking dates after seeing the data\n",
    "3. **Short windows**: May miss delayed reactions\n",
    "4. **Long windows**: May capture unrelated noise\n",
    "\n",
    "---\n",
    "\n",
    "**Next:** See `03_anomaly_detection.ipynb` to find unusual market-event patterns."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
