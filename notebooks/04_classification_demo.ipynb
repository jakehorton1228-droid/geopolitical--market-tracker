{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 04 - Market Direction Classification\n",
    "\n",
    "This notebook demonstrates **Classification** - predicting whether the market will go UP or DOWN based on geopolitical event features.\n",
    "\n",
    "---\n",
    "\n",
    "## What is Classification?\n",
    "\n",
    "Classification is a **supervised learning** task where we predict a categorical outcome:\n",
    "\n",
    "- **Input**: Event features (Goldstein scale, mentions, tone, etc.)\n",
    "- **Output**: Binary prediction (UP or DOWN)\n",
    "\n",
    "Unlike regression (which predicts a continuous value like return magnitude), classification focuses on **direction**.\n",
    "\n",
    "---\n",
    "\n",
    "## Why Logistic Regression?\n",
    "\n",
    "We use **Logistic Regression** because it's:\n",
    "\n",
    "| Property | Why It Matters |\n",
    "|----------|----------------|\n",
    "| **Interpretable** | Each coefficient tells you feature importance |\n",
    "| **Probabilistic** | Gives confidence (60% UP vs 99% UP) |\n",
    "| **Works with small data** | Doesn't need millions of samples |\n",
    "| **Industry standard** | Used at major trading firms |\n",
    "| **Fast to train** | Can retrain daily |\n",
    "\n",
    "---\n",
    "\n",
    "## Key Concepts You'll Learn\n",
    "\n",
    "1. **Sigmoid function**: Maps any value to probability [0, 1]\n",
    "2. **Decision boundary**: Where probability crosses 50%\n",
    "3. **Cross-validation**: Robust performance estimation\n",
    "4. **Confusion matrix**: Understanding prediction errors\n",
    "5. **Precision vs Recall**: Trade-offs in classification\n",
    "\n",
    "---\n",
    "\n",
    "We'll compare our **learning version** (manual gradient descent) with **production version** (sklearn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "# IMPORTS\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "#\n",
    "# Standard imports for ML notebooks:\n",
    "#   - sys/pathlib: For path manipulation\n",
    "#   - datetime: For date handling\n",
    "#   - pandas: Data manipulation\n",
    "#   - numpy: Numerical operations\n",
    "#   - matplotlib/seaborn: Visualization\n",
    "#\n",
    "# We'll also import sklearn for the production version.\n",
    "#\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import date, timedelta\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Understanding Logistic Regression\n",
    "\n",
    "### The Problem with Linear Regression\n",
    "\n",
    "If we used linear regression to predict UP (1) or DOWN (0), we'd get predictions like:\n",
    "- y = 1.5 (impossible - can't be >100% UP)\n",
    "- y = -0.3 (impossible - can't be negative probability)\n",
    "\n",
    "### The Sigmoid Solution\n",
    "\n",
    "The **sigmoid function** squashes any value into the range [0, 1]:\n",
    "\n",
    "$$\\sigma(z) = \\frac{1}{1 + e^{-z}}$$\n",
    "\n",
    "Where:\n",
    "- z = w₀ + w₁x₁ + w₂x₂ + ... (linear combination of features)\n",
    "- σ(z) = probability of class 1 (UP)\n",
    "\n",
    "### The Decision Rule\n",
    "\n",
    "- If σ(z) > 0.5 → Predict UP\n",
    "- If σ(z) ≤ 0.5 → Predict DOWN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "# SIGMOID FUNCTION VISUALIZATION\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "#\n",
    "# The sigmoid function is the heart of logistic regression.\n",
    "#\n",
    "# LEFT PLOT - The Sigmoid Curve:\n",
    "#   - X-axis: z (the linear combination w₀ + w₁x₁ + ...)\n",
    "#   - Y-axis: Probability of UP\n",
    "#   - At z=0: probability = 0.5 (the decision boundary)\n",
    "#   - As z → ∞: probability → 1\n",
    "#   - As z → -∞: probability → 0\n",
    "#\n",
    "# RIGHT PLOT - Decision Boundary in 2D:\n",
    "#   - Shows how logistic regression separates two classes\n",
    "#   - The line is where probability = 0.5\n",
    "#   - Points on one side → UP, other side → DOWN\n",
    "#\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "def sigmoid(z):\n",
    "    \"\"\"The sigmoid (logistic) function.\n",
    "    \n",
    "    Maps any real number to the range (0, 1).\n",
    "    This is how we convert a linear combination into a probability.\n",
    "    \n",
    "    Properties:\n",
    "    - sigmoid(0) = 0.5\n",
    "    - sigmoid(-∞) → 0\n",
    "    - sigmoid(+∞) → 1\n",
    "    - Derivative: sigmoid(z) * (1 - sigmoid(z)) - used in gradient descent\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# ─── LEFT: Sigmoid Curve ───\n",
    "z = np.linspace(-6, 6, 100)\n",
    "ax = axes[0]\n",
    "\n",
    "ax.plot(z, sigmoid(z), linewidth=3, color='steelblue', label='σ(z) = 1/(1+e⁻ᶻ)')\n",
    "ax.axhline(y=0.5, color='red', linestyle='--', linewidth=2, label='Decision boundary (p=0.5)')\n",
    "ax.axvline(x=0, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Shade the regions\n",
    "ax.fill_between(z[z < 0], 0, sigmoid(z[z < 0]), alpha=0.2, color='red', label='Predict DOWN')\n",
    "ax.fill_between(z[z >= 0], sigmoid(z[z >= 0]), 1, alpha=0.2, color='green', label='Predict UP')\n",
    "\n",
    "ax.set_xlabel('z = w₀ + w₁x₁ + w₂x₂ + ...', fontsize=12)\n",
    "ax.set_ylabel('Probability of UP', fontsize=12)\n",
    "ax.set_title('The Sigmoid Function\\n(Converts any z to probability)', fontsize=12)\n",
    "ax.legend(loc='right')\n",
    "ax.set_ylim(-0.1, 1.1)\n",
    "\n",
    "# Add annotations\n",
    "ax.annotate('High confidence\\nUP', xy=(4, 0.98), fontsize=10, ha='center', color='green')\n",
    "ax.annotate('High confidence\\nDOWN', xy=(-4, 0.02), fontsize=10, ha='center', color='red')\n",
    "ax.annotate('Uncertain\\n(near 50%)', xy=(0, 0.5), xytext=(2, 0.3),\n",
    "           arrowprops=dict(arrowstyle='->', color='gray'), fontsize=10)\n",
    "\n",
    "# ─── RIGHT: 2D Decision Boundary ───\n",
    "ax = axes[1]\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate sample data: UP days and DOWN days\n",
    "up_points = np.random.randn(50, 2) + [1.5, 1.5]   # Cluster in top-right\n",
    "down_points = np.random.randn(50, 2) + [-1.5, -1.5]  # Cluster in bottom-left\n",
    "\n",
    "ax.scatter(up_points[:, 0], up_points[:, 1], c='green', label='UP days', alpha=0.6, s=60)\n",
    "ax.scatter(down_points[:, 0], down_points[:, 1], c='red', label='DOWN days', alpha=0.6, s=60)\n",
    "\n",
    "# Decision boundary (approximate line where P(UP) = 0.5)\n",
    "x_line = np.linspace(-4, 4, 100)\n",
    "ax.plot(x_line, -x_line, 'k--', linewidth=2, label='Decision boundary')\n",
    "\n",
    "# Shade regions\n",
    "ax.fill_between(x_line, -x_line, 5, alpha=0.1, color='green')\n",
    "ax.fill_between(x_line, -x_line, -5, alpha=0.1, color='red')\n",
    "\n",
    "ax.set_xlabel('Feature 1 (e.g., Average Goldstein Scale)', fontsize=11)\n",
    "ax.set_ylabel('Feature 2 (e.g., Total Mentions)', fontsize=11)\n",
    "ax.set_title('Logistic Regression Classification\\n(Separating UP from DOWN days)', fontsize=12)\n",
    "ax.legend()\n",
    "ax.set_xlim(-4, 4)\n",
    "ax.set_ylim(-4, 4)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nHow Logistic Regression Makes Predictions:\")\n",
    "print(\"═\" * 60)\n",
    "print(\"\")\n",
    "print(\"1. COMPUTE LINEAR COMBINATION:\")\n",
    "print(\"   z = w₀ + w₁(goldstein) + w₂(mentions) + w₃(tone) + ...\")\n",
    "print(\"\")\n",
    "print(\"2. APPLY SIGMOID:\")\n",
    "print(\"   P(UP) = 1 / (1 + e⁻ᶻ)\")\n",
    "print(\"\")\n",
    "print(\"3. MAKE DECISION:\")\n",
    "print(\"   If P(UP) > 0.5 → Predict UP\")\n",
    "print(\"   If P(UP) ≤ 0.5 → Predict DOWN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 2. Learning Version: Manual Implementation\n",
    "\n",
    "Our **learning version** implements logistic regression from scratch using **gradient descent**.\n",
    "\n",
    "### Gradient Descent Algorithm\n",
    "\n",
    "1. Initialize weights randomly\n",
    "2. For each iteration:\n",
    "   - Make predictions using current weights\n",
    "   - Calculate the loss (how wrong are we?)\n",
    "   - Compute gradients (which direction improves loss?)\n",
    "   - Update weights in that direction\n",
    "3. Repeat until convergence\n",
    "\n",
    "### The Loss Function\n",
    "\n",
    "We use **log loss** (binary cross-entropy):\n",
    "\n",
    "$$L = -\\frac{1}{n}\\sum[y\\log(p) + (1-y)\\log(1-p)]$$\n",
    "\n",
    "This penalizes confident wrong predictions more than uncertain ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "# LEARNING VERSION: MarketClassifier\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "#\n",
    "# Our educational implementation shows the complete training process:\n",
    "#\n",
    "# Key parameters:\n",
    "#   - learning_rate (default 0.01):\n",
    "#     * How big steps we take during gradient descent\n",
    "#     * Too high → overshooting, too low → slow convergence\n",
    "#     * 0.01 is a safe starting point\n",
    "#\n",
    "#   - max_iterations (default 1000):\n",
    "#     * Maximum training epochs\n",
    "#     * Usually converges before this\n",
    "#\n",
    "#   - regularization (default 0.01):\n",
    "#     * L2 regularization strength (λ)\n",
    "#     * Prevents overfitting by penalizing large weights\n",
    "#     * Higher → simpler model, lower → more complex model\n",
    "#\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "from src.analysis.classification import MarketClassifier, explain_classification\n",
    "\n",
    "# Create classifier with explicit parameters\n",
    "classifier = MarketClassifier(\n",
    "    learning_rate=0.01,      # Step size for gradient descent\n",
    "    max_iterations=1000,     # Maximum training epochs\n",
    "    regularization=0.01,     # L2 penalty (prevents overfitting)\n",
    ")\n",
    "\n",
    "print(\"Classifier Configuration\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"  Learning rate (α): {classifier.learning_rate}\")\n",
    "print(f\"  Max iterations: {classifier.max_iterations}\")\n",
    "print(f\"  Regularization (λ): {classifier.regularization}\")\n",
    "print()\n",
    "print(\"What these mean:\")\n",
    "print(f\"  • α = {classifier.learning_rate}: Each step adjusts weights by α × gradient\")\n",
    "print(f\"  • λ = {classifier.regularization}: Adds λ×||w||² penalty to prevent overfitting\")\n",
    "print(f\"  • Stop after {classifier.max_iterations} iterations or when converged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "# TRAINING THE CLASSIFIER\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "#\n",
    "# The train() method:\n",
    "#   1. Fetches event and market data for the symbol\n",
    "#   2. Prepares features (Goldstein, mentions, tone, etc.)\n",
    "#   3. Creates labels (1 = UP, 0 = DOWN based on return)\n",
    "#   4. Runs gradient descent to learn weights\n",
    "#   5. Returns metrics (accuracy, precision, recall, F1)\n",
    "#\n",
    "# We use 6 months of data to have enough training samples.\n",
    "#\n",
    "# verbose=True shows the training progress.\n",
    "#\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "# Define date range (6 months of data)\n",
    "end_date = date.today()\n",
    "start_date = end_date - timedelta(days=180)\n",
    "\n",
    "print(f\"Training classifier for CL=F (Crude Oil)\")\n",
    "print(f\"Date range: {start_date} to {end_date}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Train with verbose output\n",
    "metrics = classifier.train('CL=F', start_date, end_date, verbose=True)\n",
    "\n",
    "if metrics:\n",
    "    print(\"\\nTraining Complete!\")\n",
    "    print(f\"  Training samples: {metrics.n_samples}\")\n",
    "    print(f\"  Accuracy: {metrics.accuracy:.2%}\")\n",
    "else:\n",
    "    print(\"\\nTraining failed - insufficient data.\")\n",
    "    print(\"Ensure the database has both event and market data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "# TRAINING HISTORY VISUALIZATION\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "#\n",
    "# The learning version tracks training progress:\n",
    "#   - Loss: How wrong are our predictions? (should decrease)\n",
    "#   - Coefficient change: Are weights still updating? (should decrease)\n",
    "#\n",
    "# LEFT PLOT - Loss Over Iterations:\n",
    "#   - Should show a decreasing curve\n",
    "#   - Flat at the end = converged\n",
    "#   - Increasing = something wrong (learning rate too high?)\n",
    "#\n",
    "# RIGHT PLOT - Convergence:\n",
    "#   - Shows the max change in any coefficient per iteration\n",
    "#   - When this gets small, we've converged\n",
    "#\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "if classifier.training_history:\n",
    "    history_df = pd.DataFrame(classifier.training_history)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # ─── LEFT: Loss Over Iterations ───\n",
    "    axes[0].plot(history_df['iteration'], history_df['loss'], linewidth=2, color='steelblue')\n",
    "    axes[0].set_xlabel('Iteration', fontsize=12)\n",
    "    axes[0].set_ylabel('Log Loss', fontsize=12)\n",
    "    axes[0].set_title('Training Loss\\n(Lower = Better Fit)', fontsize=12)\n",
    "    \n",
    "    # Mark initial and final loss\n",
    "    axes[0].scatter([0], [history_df['loss'].iloc[0]], color='red', s=100, zorder=5, label=f'Initial: {history_df[\"loss\"].iloc[0]:.4f}')\n",
    "    axes[0].scatter([len(history_df)-1], [history_df['loss'].iloc[-1]], color='green', s=100, zorder=5, label=f'Final: {history_df[\"loss\"].iloc[-1]:.4f}')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    # ─── RIGHT: Coefficient Changes ───\n",
    "    axes[1].plot(history_df['iteration'], history_df['coefficient_change'], linewidth=2, color='orange')\n",
    "    axes[1].set_xlabel('Iteration', fontsize=12)\n",
    "    axes[1].set_ylabel('Max Coefficient Change', fontsize=12)\n",
    "    axes[1].set_title('Convergence\\n(Smaller = More Stable)', fontsize=12)\n",
    "    axes[1].set_yscale('log')  # Log scale to see small changes\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nTraining Analysis:\")\n",
    "    print(\"─\" * 50)\n",
    "    print(f\"  Total iterations: {len(history_df)}\")\n",
    "    print(f\"  Loss reduction: {history_df['loss'].iloc[0]:.4f} → {history_df['loss'].iloc[-1]:.4f}\")\n",
    "    print(f\"  Improvement: {(1 - history_df['loss'].iloc[-1]/history_df['loss'].iloc[0])*100:.1f}%\")\n",
    "else:\n",
    "    print(\"No training history available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "# FEATURE IMPORTANCE\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "#\n",
    "# One of logistic regression's biggest advantages: INTERPRETABILITY.\n",
    "#\n",
    "# Each coefficient tells you:\n",
    "#   - Magnitude: How important is this feature?\n",
    "#   - Sign: Does it increase (+) or decrease (-) P(UP)?\n",
    "#\n",
    "# Features used:\n",
    "#   - goldstein_mean: Average Goldstein score (conflict vs cooperation)\n",
    "#   - goldstein_min: Worst event of the day\n",
    "#   - goldstein_max: Best event of the day\n",
    "#   - mentions_total: Total media mentions\n",
    "#   - avg_tone: Average media tone\n",
    "#   - conflict_count: Number of conflict events\n",
    "#   - cooperation_count: Number of cooperation events\n",
    "#\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "if classifier.is_trained:\n",
    "    importance = classifier.get_feature_importance('CL=F')\n",
    "    \n",
    "    print(\"Feature Importance (Absolute Coefficient Values)\")\n",
    "    print(\"=\" * 60)\n",
    "    print()\n",
    "    print(f\"{'Feature':<25} {'Importance':>12} {'Effect on P(UP)':>18}\")\n",
    "    print(\"─\" * 60)\n",
    "    \n",
    "    for name, imp in sorted(importance.items(), key=lambda x: -x[1]):\n",
    "        if name == 'intercept':\n",
    "            continue\n",
    "        # Get actual coefficient for direction\n",
    "        coef = classifier.symbol_models['CL=F'][classifier.feature_names.index(name)]\n",
    "        direction = '↑ increases' if coef > 0 else '↓ decreases'\n",
    "        print(f\"  {name:<23} {imp:>10.4f}   {direction}\")\n",
    "    \n",
    "    print(\"─\" * 60)\n",
    "    print()\n",
    "    print(\"Interpretation:\")\n",
    "    print(\"  • Higher importance = stronger predictor\")\n",
    "    print(\"  • ↑ = positive coefficient (increases probability of UP)\")\n",
    "    print(\"  • ↓ = negative coefficient (decreases probability of UP)\")\n",
    "else:\n",
    "    print(\"Classifier not trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "# MAKING A PREDICTION\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "#\n",
    "# Let's make a prediction for a hypothetical day.\n",
    "#\n",
    "# The predict() method:\n",
    "#   1. Takes a dictionary of feature values\n",
    "#   2. Computes z = w₀ + w₁x₁ + w₂x₂ + ...\n",
    "#   3. Applies sigmoid to get P(UP)\n",
    "#   4. Returns prediction, probability, and confidence level\n",
    "#\n",
    "# Confidence levels:\n",
    "#   - LOW: 50-60% (nearly random)\n",
    "#   - MEDIUM: 60-75% (some signal)\n",
    "#   - HIGH: 75%+ (strong signal)\n",
    "#\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "if classifier.is_trained:\n",
    "    # Scenario: A day with negative geopolitical events\n",
    "    sample_features = {\n",
    "        'goldstein_mean': -3.5,      # Negative events on average\n",
    "        'goldstein_min': -7.0,       # Some severe conflict\n",
    "        'goldstein_max': 2.0,        # Some cooperation too\n",
    "        'mentions_total': 500,       # Moderate media coverage\n",
    "        'avg_tone': -2.0,            # Negative tone\n",
    "        'conflict_count': 5,         # Several conflicts\n",
    "        'cooperation_count': 2,      # Some cooperation\n",
    "    }\n",
    "    \n",
    "    print(\"Sample Prediction\")\n",
    "    print(\"=\" * 50)\n",
    "    print()\n",
    "    print(\"Input Features:\")\n",
    "    for k, v in sample_features.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "    print()\n",
    "    \n",
    "    prediction = classifier.predict('CL=F', sample_features)\n",
    "    \n",
    "    if prediction:\n",
    "        print(explain_classification(prediction))\n",
    "    else:\n",
    "        print(\"Prediction failed.\")\n",
    "else:\n",
    "    print(\"Classifier not trained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 3. Production Version: sklearn\n",
    "\n",
    "The **production version** uses sklearn, the industry-standard ML library.\n",
    "\n",
    "### Advantages over Learning Version\n",
    "\n",
    "| Feature | Learning | Production |\n",
    "|---------|----------|------------|\n",
    "| Optimizer | Manual gradient descent | LBFGS (quasi-Newton) |\n",
    "| Cross-validation | Not included | Built-in k-fold |\n",
    "| Regularization | Basic L2 | L1, L2, ElasticNet |\n",
    "| Scalability | Single-threaded | Multi-threaded |\n",
    "| Reliability | Educational | Battle-tested |\n",
    "\n",
    "### Cross-Validation\n",
    "\n",
    "**Cross-validation** gives a more robust accuracy estimate:\n",
    "1. Split data into k folds (default 5)\n",
    "2. Train on k-1 folds, test on remaining fold\n",
    "3. Repeat k times, average the results\n",
    "\n",
    "This prevents overfitting to a single train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "# PRODUCTION VERSION: ProductionClassifier\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "#\n",
    "# sklearn's LogisticRegression with cross-validation.\n",
    "#\n",
    "# Key differences from learning version:\n",
    "#   - Uses LBFGS optimizer (faster, more stable)\n",
    "#   - Automatic cross-validation (5-fold by default)\n",
    "#   - Computes confidence intervals on accuracy\n",
    "#\n",
    "# The metrics returned include:\n",
    "#   - accuracy: Overall correct predictions\n",
    "#   - precision: When we predict UP, how often correct?\n",
    "#   - recall: Of actual UPs, how many did we catch?\n",
    "#   - f1_score: Harmonic mean of precision and recall\n",
    "#   - cv_accuracy: Cross-validated accuracy (more reliable)\n",
    "#   - cv_std: Standard deviation across folds\n",
    "#\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "from src.analysis.production_classifier import ProductionClassifier\n",
    "\n",
    "# Create production classifier\n",
    "prod_classifier = ProductionClassifier()\n",
    "\n",
    "print(f\"Training production classifier for CL=F\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "prod_metrics = prod_classifier.train('CL=F', start_date, end_date)\n",
    "\n",
    "if prod_metrics:\n",
    "    print(\"\\nProduction Version Results\")\n",
    "    print(\"─\" * 40)\n",
    "    print()\n",
    "    print(\"Training Metrics:\")\n",
    "    print(f\"  Accuracy:  {prod_metrics.accuracy:.2%}\")\n",
    "    print(f\"  Precision: {prod_metrics.precision:.2%}\")\n",
    "    print(f\"  Recall:    {prod_metrics.recall:.2%}\")\n",
    "    print(f\"  F1 Score:  {prod_metrics.f1_score:.2%}\")\n",
    "    print()\n",
    "    print(\"Cross-Validation (5-fold):\")\n",
    "    print(f\"  CV Accuracy: {prod_metrics.cv_accuracy:.2%} (±{prod_metrics.cv_std*2:.2%})\")\n",
    "    print()\n",
    "    print(\"Interpretation:\")\n",
    "    if prod_metrics.cv_accuracy > 0.55:\n",
    "        print(\"  ✓ Model performs better than random (50%)!\")\n",
    "    else:\n",
    "        print(\"  ✗ Model near random - events may not predict this market well\")\n",
    "else:\n",
    "    print(\"Training failed - insufficient data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "# FEATURE IMPORTANCE VISUALIZATION\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "#\n",
    "# Visual representation of which features drive predictions.\n",
    "#\n",
    "# Bar chart interpretation:\n",
    "#   - Longer bar = more important feature\n",
    "#   - Green bar = positive coefficient (increases P(UP))\n",
    "#   - Red bar = negative coefficient (decreases P(UP))\n",
    "#\n",
    "# This is one of logistic regression's key strengths:\n",
    "# Unlike neural networks, you can explain WHY a prediction was made!\n",
    "#\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "if prod_classifier.models:\n",
    "    prod_importance = prod_classifier.get_feature_importance('CL=F')\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    features = list(prod_importance.keys())\n",
    "    values = list(prod_importance.values())\n",
    "    \n",
    "    # Get actual coefficients for coloring\n",
    "    model = prod_classifier.models['CL=F']\n",
    "    coefs = dict(zip(prod_classifier.feature_names, model.coef_[0]))\n",
    "    colors = ['green' if coefs.get(f, 0) > 0 else 'red' for f in features]\n",
    "    \n",
    "    # Sort by importance\n",
    "    sorted_idx = np.argsort(values)[::-1]\n",
    "    features_sorted = [features[i] for i in sorted_idx]\n",
    "    values_sorted = [values[i] for i in sorted_idx]\n",
    "    colors_sorted = [colors[i] for i in sorted_idx]\n",
    "    \n",
    "    ax.barh(features_sorted, values_sorted, color=colors_sorted, alpha=0.7, edgecolor='black')\n",
    "    ax.set_xlabel('Absolute Coefficient Value', fontsize=12)\n",
    "    ax.set_ylabel('Feature', fontsize=12)\n",
    "    ax.set_title('Feature Importance\\n(Green = ↑ P(UP), Red = ↓ P(UP))', fontsize=12)\n",
    "    \n",
    "    # Add a legend\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [\n",
    "        Patch(facecolor='green', alpha=0.7, label='Increases P(UP)'),\n",
    "        Patch(facecolor='red', alpha=0.7, label='Decreases P(UP)'),\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='lower right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nFeature Analysis:\")\n",
    "    print(\"─\" * 50)\n",
    "    top_feature = features_sorted[0]\n",
    "    top_direction = 'increases' if coefs.get(top_feature, 0) > 0 else 'decreases'\n",
    "    print(f\"  Most important: {top_feature}\")\n",
    "    print(f\"  Effect: Higher {top_feature} → {top_direction} P(UP)\")\n",
    "else:\n",
    "    print(\"No model trained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## 4. Training Across Multiple Markets\n",
    "\n",
    "Let's see how well our model performs on different markets.\n",
    "\n",
    "Different markets may respond differently to geopolitical events:\n",
    "- **Oil (CL=F)**: Highly sensitive to Middle East events\n",
    "- **Gold (GC=F)**: Safe haven, may rise during uncertainty\n",
    "- **SPY**: Broad market, diverse factors\n",
    "- **VIX**: Fear gauge, inversely related to sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "# MULTI-MARKET TRAINING\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "#\n",
    "# Train separate models for each market.\n",
    "#\n",
    "# Why separate models?\n",
    "#   - Each market has different sensitivities\n",
    "#   - Oil reacts differently to events than gold\n",
    "#   - A unified model would be too generic\n",
    "#\n",
    "# We'll compare:\n",
    "#   - Training accuracy: How well we fit the training data\n",
    "#   - CV accuracy: How well we generalize (more important!)\n",
    "#\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "symbols = ['CL=F', 'GC=F', 'SPY', '^VIX', 'EURUSD=X']\n",
    "symbol_names = {\n",
    "    'CL=F': 'Crude Oil',\n",
    "    'GC=F': 'Gold',\n",
    "    'SPY': 'S&P 500',\n",
    "    '^VIX': 'Volatility',\n",
    "    'EURUSD=X': 'EUR/USD',\n",
    "}\n",
    "\n",
    "all_results = {}\n",
    "\n",
    "print(\"Training classifiers for multiple markets...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for symbol in symbols:\n",
    "    metrics = prod_classifier.train(symbol, start_date, end_date)\n",
    "    if metrics:\n",
    "        all_results[symbol] = metrics\n",
    "        status = '✓' if metrics.cv_accuracy > 0.52 else '○'\n",
    "        print(f\"  {status} {symbol_names.get(symbol, symbol)}: \"\n",
    "              f\"Acc={metrics.accuracy:.1%}, CV={metrics.cv_accuracy:.1%} (±{metrics.cv_std*2:.1%})\")\n",
    "    else:\n",
    "        print(f\"  ✗ {symbol_names.get(symbol, symbol)}: Insufficient data\")\n",
    "\n",
    "print()\n",
    "print(\"Legend: ✓ = better than random, ○ = near random, ✗ = no data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "# CROSS-MARKET COMPARISON VISUALIZATION\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "#\n",
    "# LEFT PLOT - Accuracy Comparison:\n",
    "#   - Blue bars: Training accuracy (may overfit)\n",
    "#   - Green bars: CV accuracy (more realistic)\n",
    "#   - Error bars: ±2 std (95% confidence interval)\n",
    "#   - Red dashed line: Random baseline (50%)\n",
    "#\n",
    "# RIGHT PLOT - F1 Score:\n",
    "#   - Balances precision and recall\n",
    "#   - Green = good (>0.5), Orange = okay (0.4-0.5), Red = poor (<0.4)\n",
    "#\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "if all_results:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # ─── LEFT: Accuracy Comparison ───\n",
    "    ax = axes[0]\n",
    "    \n",
    "    symbols_list = list(all_results.keys())\n",
    "    names = [symbol_names.get(s, s) for s in symbols_list]\n",
    "    accuracies = [all_results[s].accuracy for s in symbols_list]\n",
    "    cv_accuracies = [all_results[s].cv_accuracy for s in symbols_list]\n",
    "    cv_stds = [all_results[s].cv_std for s in symbols_list]\n",
    "    \n",
    "    x = np.arange(len(symbols_list))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = ax.bar(x - width/2, accuracies, width, label='Training Accuracy', \n",
    "                   color='steelblue', alpha=0.7)\n",
    "    bars2 = ax.bar(x + width/2, cv_accuracies, width, label='CV Accuracy', \n",
    "                   color='green', alpha=0.7, yerr=[s*2 for s in cv_stds], capsize=5)\n",
    "    \n",
    "    ax.axhline(y=0.5, color='red', linestyle='--', linewidth=2, label='Random (50%)')\n",
    "    \n",
    "    ax.set_xlabel('Market', fontsize=12)\n",
    "    ax.set_ylabel('Accuracy', fontsize=12)\n",
    "    ax.set_title('Classification Accuracy by Market\\n(CV accuracy is more reliable)', fontsize=12)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(names, rotation=15)\n",
    "    ax.legend()\n",
    "    ax.set_ylim(0, 1)\n",
    "    \n",
    "    # ─── RIGHT: F1 Scores ───\n",
    "    ax = axes[1]\n",
    "    \n",
    "    f1_scores = [all_results[s].f1_score for s in symbols_list]\n",
    "    \n",
    "    # Color by performance\n",
    "    colors = ['green' if f > 0.5 else 'orange' if f > 0.4 else 'red' for f in f1_scores]\n",
    "    \n",
    "    ax.bar(names, f1_scores, color=colors, alpha=0.7, edgecolor='black')\n",
    "    ax.axhline(y=0.5, color='red', linestyle='--', linewidth=2, label='Baseline')\n",
    "    \n",
    "    ax.set_xlabel('Market', fontsize=12)\n",
    "    ax.set_ylabel('F1 Score', fontsize=12)\n",
    "    ax.set_title('F1 Score by Market\\n(Balances Precision and Recall)', fontsize=12)\n",
    "    ax.set_xticklabels(names, rotation=15)\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\nSummary:\")\n",
    "    print(\"─\" * 50)\n",
    "    best_market = max(all_results.items(), key=lambda x: x[1].cv_accuracy)\n",
    "    print(f\"  Best market: {symbol_names.get(best_market[0], best_market[0])} \"\n",
    "          f\"(CV accuracy: {best_market[1].cv_accuracy:.1%})\")\n",
    "    \n",
    "    above_random = sum(1 for m in all_results.values() if m.cv_accuracy > 0.52)\n",
    "    print(f\"  Markets beating random: {above_random}/{len(all_results)}\")\n",
    "else:\n",
    "    print(\"No results to visualize.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## 5. Understanding the Metrics\n",
    "\n",
    "Classification metrics can be confusing. Let's break them down.\n",
    "\n",
    "### The Confusion Matrix\n",
    "\n",
    "```\n",
    "                 Predicted\n",
    "               UP      DOWN\n",
    "        Actual UP:  TP       FN\n",
    "              DOWN: FP       TN\n",
    "```\n",
    "\n",
    "- **TP (True Positive)**: Predicted UP, actually UP\n",
    "- **TN (True Negative)**: Predicted DOWN, actually DOWN\n",
    "- **FP (False Positive)**: Predicted UP, actually DOWN (oops!)\n",
    "- **FN (False Negative)**: Predicted DOWN, actually UP (missed opportunity!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "# METRIC EXPLANATIONS\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "#\n",
    "# Understanding what each metric tells you:\n",
    "#\n",
    "# ACCURACY:\n",
    "#   - (TP + TN) / Total\n",
    "#   - How often are we correct overall?\n",
    "#   - Can be misleading with imbalanced classes\n",
    "#\n",
    "# PRECISION:\n",
    "#   - TP / (TP + FP)\n",
    "#   - When we predict UP, how often are we right?\n",
    "#   - \"Don't cry wolf\" - minimize false alarms\n",
    "#\n",
    "# RECALL (Sensitivity):\n",
    "#   - TP / (TP + FN)\n",
    "#   - Of all actual UPs, how many did we catch?\n",
    "#   - \"Don't miss any wolves\" - minimize missed opportunities\n",
    "#\n",
    "# F1 SCORE:\n",
    "#   - 2 × (Precision × Recall) / (Precision + Recall)\n",
    "#   - Harmonic mean - balances both concerns\n",
    "#   - Use when you care about both equally\n",
    "#\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"UNDERSTANDING CLASSIFICATION METRICS\")\n",
    "print(\"═\" * 60)\n",
    "print()\n",
    "print(\"THE CONFUSION MATRIX:\")\n",
    "print(\"─\" * 40)\n",
    "print(\"                      Predicted\")\n",
    "print(\"                    UP       DOWN\")\n",
    "print(\"          Actual UP:  TP        FN\")\n",
    "print(\"                DOWN: FP        TN\")\n",
    "print()\n",
    "print(\"METRICS FROM THE MATRIX:\")\n",
    "print(\"─\" * 40)\n",
    "print()\n",
    "print(\"  ACCURACY  = (TP + TN) / Total\")\n",
    "print(\"            = How often are we correct overall?\")\n",
    "print(\"            → Good for balanced datasets\")\n",
    "print()\n",
    "print(\"  PRECISION = TP / (TP + FP)\")\n",
    "print(\"            = When we predict UP, how often correct?\")\n",
    "print(\"            → 'Don't cry wolf' - avoid false alarms\")\n",
    "print()\n",
    "print(\"  RECALL    = TP / (TP + FN)\")\n",
    "print(\"            = Of all actual UPs, how many caught?\")\n",
    "print(\"            → 'Don't miss opportunities'\")\n",
    "print()\n",
    "print(\"  F1 SCORE  = 2 × (Precision × Recall) / (Precision + Recall)\")\n",
    "print(\"            = Harmonic mean - balances both\")\n",
    "print(\"            → Use when both matter equally\")\n",
    "print()\n",
    "print(\"CROSS-VALIDATION:\")\n",
    "print(\"─\" * 40)\n",
    "print(\"  = Average accuracy across multiple train/test splits\")\n",
    "print(\"  = More robust estimate of real-world performance\")\n",
    "print(\"  = Prevents overfitting to a single split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "# CONFUSION MATRIX VISUALIZATION\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "#\n",
    "# Visual representation of a confusion matrix.\n",
    "#\n",
    "# The heatmap shows:\n",
    "#   - Darker blue = more predictions in that cell\n",
    "#   - Diagonal = correct predictions (want these high)\n",
    "#   - Off-diagonal = errors (want these low)\n",
    "#\n",
    "# Reading the matrix:\n",
    "#   - Top-left (TP): Correctly predicted UP\n",
    "#   - Top-right (FN): Missed UP (predicted DOWN)\n",
    "#   - Bottom-left (FP): False alarm (predicted UP, was DOWN)\n",
    "#   - Bottom-right (TN): Correctly predicted DOWN\n",
    "#\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Example confusion matrix\n",
    "cm = np.array([\n",
    "    [45, 10],   # Actual UP: 45 correct (TP), 10 missed (FN)\n",
    "    [15, 30]    # Actual DOWN: 15 false alarms (FP), 30 correct (TN)\n",
    "])\n",
    "\n",
    "# Create heatmap\n",
    "sns.heatmap(\n",
    "    cm, \n",
    "    annot=True, \n",
    "    fmt='d', \n",
    "    cmap='Blues',\n",
    "    xticklabels=['Predict UP', 'Predict DOWN'],\n",
    "    yticklabels=['Actual UP', 'Actual DOWN'],\n",
    "    ax=ax, \n",
    "    annot_kws={'size': 16}\n",
    ")\n",
    "\n",
    "ax.set_title('Example Confusion Matrix', fontsize=14)\n",
    "\n",
    "# Calculate metrics from this matrix\n",
    "tp, fn = cm[0]\n",
    "fp, tn = cm[1]\n",
    "total = cm.sum()\n",
    "\n",
    "accuracy = (tp + tn) / total\n",
    "precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "# Add metrics as text\n",
    "metrics_text = f'Accuracy: {accuracy:.2%}\\nPrecision: {precision:.2%}\\nRecall: {recall:.2%}\\nF1: {f1:.2%}'\n",
    "ax.text(2.5, 0.5, metrics_text, fontsize=12, verticalalignment='center',\n",
    "        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "# Add cell labels\n",
    "ax.text(-0.4, 0.5, 'TP=45', fontsize=10, color='green', fontweight='bold', ha='right')\n",
    "ax.text(-0.4, 1.5, 'FP=15', fontsize=10, color='red', fontweight='bold', ha='right')\n",
    "ax.text(2.4, 0.5, 'FN=10', fontsize=10, color='red', fontweight='bold', ha='left')\n",
    "ax.text(2.4, 1.5, 'TN=30', fontsize=10, color='green', fontweight='bold', ha='left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nReading this confusion matrix:\")\n",
    "print(\"─\" * 50)\n",
    "print(f\"  • {tp} times we correctly predicted UP (True Positive)\")\n",
    "print(f\"  • {tn} times we correctly predicted DOWN (True Negative)\")\n",
    "print(f\"  • {fn} times we missed an UP (False Negative)\")\n",
    "print(f\"  • {fp} times we falsely predicted UP (False Positive)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## 6. Making Predictions\n",
    "\n",
    "Let's use our trained model to make predictions for different scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "# SCENARIO-BASED PREDICTIONS\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "#\n",
    "# We'll test three scenarios:\n",
    "#\n",
    "# 1. CONFLICT DAY:\n",
    "#    - Negative Goldstein scores\n",
    "#    - High media mentions\n",
    "#    - Many conflict events\n",
    "#    → Expect model to predict DOWN with higher confidence\n",
    "#\n",
    "# 2. PEACEFUL DAY:\n",
    "#    - Positive Goldstein scores\n",
    "#    - Moderate coverage\n",
    "#    - Cooperation events\n",
    "#    → Expect model to predict UP with higher confidence\n",
    "#\n",
    "# 3. MIXED DAY:\n",
    "#    - Neutral Goldstein\n",
    "#    - Mix of conflict and cooperation\n",
    "#    → Expect model to be uncertain (near 50%)\n",
    "#\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "if prod_classifier.models:\n",
    "    scenarios = [\n",
    "        ('CONFLICT DAY', {\n",
    "            'goldstein_mean': -5.0,      # Negative events on average\n",
    "            'goldstein_min': -9.0,       # Severe conflict\n",
    "            'goldstein_max': -2.0,       # Even best event was negative\n",
    "            'mentions_total': 1000,      # High media coverage\n",
    "            'avg_tone': -4.0,            # Very negative tone\n",
    "            'conflict_count': 10,        # Many conflicts\n",
    "            'cooperation_count': 1,      # Almost no cooperation\n",
    "        }),\n",
    "        ('PEACEFUL DAY', {\n",
    "            'goldstein_mean': 4.0,       # Positive events\n",
    "            'goldstein_min': 1.0,        # Even worst event was positive\n",
    "            'goldstein_max': 7.0,        # Some great cooperation\n",
    "            'mentions_total': 300,       # Lower media attention\n",
    "            'avg_tone': 2.0,             # Positive tone\n",
    "            'conflict_count': 1,         # Minimal conflict\n",
    "            'cooperation_count': 8,      # Lots of cooperation\n",
    "        }),\n",
    "        ('MIXED DAY', {\n",
    "            'goldstein_mean': 0.0,       # Neutral average\n",
    "            'goldstein_min': -5.0,       # Some conflict\n",
    "            'goldstein_max': 5.0,        # Some cooperation\n",
    "            'mentions_total': 500,       # Moderate coverage\n",
    "            'avg_tone': 0.0,             # Neutral tone\n",
    "            'conflict_count': 3,         # Some conflict\n",
    "            'cooperation_count': 3,      # Some cooperation\n",
    "        }),\n",
    "    ]\n",
    "    \n",
    "    print(\"SCENARIO-BASED PREDICTIONS FOR OIL (CL=F)\")\n",
    "    print(\"═\" * 60)\n",
    "    \n",
    "    for name, features in scenarios:\n",
    "        print(f\"\\n{name}\")\n",
    "        print(\"─\" * 40)\n",
    "        \n",
    "        # Key feature summary\n",
    "        print(f\"  Goldstein: {features['goldstein_mean']:+.1f} (range: {features['goldstein_min']:+.1f} to {features['goldstein_max']:+.1f})\")\n",
    "        print(f\"  Mentions: {features['mentions_total']}, Tone: {features['avg_tone']:+.1f}\")\n",
    "        print(f\"  Conflicts: {features['conflict_count']}, Cooperations: {features['cooperation_count']}\")\n",
    "        \n",
    "        pred = prod_classifier.predict('CL=F', features)\n",
    "        if pred:\n",
    "            confidence_bar = '█' * int(pred.probability * 20)\n",
    "            print(f\"\\n  → Prediction: {pred.prediction}\")\n",
    "            print(f\"  → P(UP): {pred.probability:.1%} [{confidence_bar:<20}]\")\n",
    "            print(f\"  → Confidence: {pred.confidence.upper()}\")\n",
    "        else:\n",
    "            print(\"  → Prediction failed\")\n",
    "    \n",
    "    print(\"\\n\" + \"═\" * 60)\n",
    "    print(\"INTERPRETATION:\")\n",
    "    print(\"  • Conflict days → model predicts DOWN (lower P(UP))\")\n",
    "    print(\"  • Peaceful days → model predicts UP (higher P(UP))\")\n",
    "    print(\"  • Mixed days → model is uncertain (near 50%)\")\n",
    "else:\n",
    "    print(\"No models trained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Classification** predicts market direction (UP/DOWN) from geopolitical event features.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "| Concept | Description | Formula/Notes |\n",
    "|---------|-------------|---------------|\n",
    "| **Sigmoid** | Maps any value to [0,1] | σ(z) = 1/(1+e⁻ᶻ) |\n",
    "| **Decision boundary** | Where P(UP) = 0.5 | z = 0 in sigmoid |\n",
    "| **Accuracy** | Overall correctness | (TP+TN)/Total |\n",
    "| **Precision** | When predict UP, how often right | TP/(TP+FP) |\n",
    "| **Recall** | Of actual UPs, how many caught | TP/(TP+FN) |\n",
    "| **F1 Score** | Harmonic mean of P & R | 2×P×R/(P+R) |\n",
    "| **Cross-validation** | Robust accuracy estimate | Average across k folds |\n",
    "\n",
    "---\n",
    "\n",
    "### Two Implementations\n",
    "\n",
    "| Version | Class | Key Features |\n",
    "|---------|-------|-------------|\n",
    "| **Learning** | `MarketClassifier` | Manual gradient descent, shows the math |\n",
    "| **Production** | `ProductionClassifier` | sklearn, cross-validation, ready for use |\n",
    "\n",
    "---\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Logistic regression is interpretable** - coefficients explain predictions\n",
    "2. **Cross-validation > training accuracy** - always report CV scores\n",
    "3. **>50% is meaningful** - markets are hard to predict!\n",
    "4. **Different markets, different models** - oil ≠ gold ≠ equities\n",
    "\n",
    "---\n",
    "\n",
    "### Limitations\n",
    "\n",
    "- **Markets are inherently unpredictable** - even 55% is impressive\n",
    "- **Events are just one factor** - earnings, rates, technicals matter too\n",
    "- **Past patterns may not persist** - regimes change\n",
    "- **Not financial advice** - this is educational!\n",
    "\n",
    "---\n",
    "\n",
    "### Use Cases\n",
    "\n",
    "| Use Case | Why Good |\n",
    "|----------|----------|\n",
    "| **Portfolio demonstration** | Shows ML skills, finance knowledge |\n",
    "| **Learning ML fundamentals** | Classification, CV, metrics |\n",
    "| **Interview prep** | Explain logistic regression, feature importance |\n",
    "| **Research baseline** | Compare with more complex models |\n",
    "\n",
    "---\n",
    "\n",
    "**Congratulations!** You've completed the notebook series. You now understand:\n",
    "1. **EDA** - Exploring data\n",
    "2. **Event Studies** - Measuring event impact\n",
    "3. **Anomaly Detection** - Finding unusual patterns\n",
    "4. **Classification** - Predicting direction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
