{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 03 - Anomaly Detection\n",
    "\n",
    "This notebook demonstrates **Anomaly Detection** - finding unusual patterns in market-event relationships.\n",
    "\n",
    "---\n",
    "\n",
    "## What is Anomaly Detection?\n",
    "\n",
    "Anomaly detection (also called **outlier detection**) identifies data points that deviate significantly from the expected pattern. In finance, this is crucial for:\n",
    "\n",
    "- **Risk management**: Detecting unusual market moves before they escalate\n",
    "- **Alpha generation**: Finding mispricings or overreactions\n",
    "- **Fraud detection**: Identifying suspicious trading patterns\n",
    "- **Market surveillance**: Regulators use it to spot manipulation\n",
    "\n",
    "---\n",
    "\n",
    "## Two Types of Anomalies We Detect\n",
    "\n",
    "| Type | Description | Example | Possible Cause |\n",
    "|------|-------------|---------|----------------|\n",
    "| **Unexplained Move** | Big market move, no major event | Oil jumps 5%, no news | Insider trading, unreported event |\n",
    "| **Muted Response** | Major event, small market reaction | War breaks out, oil flat | Already priced in, market skepticism |\n",
    "\n",
    "---\n",
    "\n",
    "## Methods Used\n",
    "\n",
    "1. **Z-score analysis** (statistical threshold) - Simple, interpretable\n",
    "2. **Isolation Forest** (machine learning) - Robust, handles multivariate data\n",
    "3. **Event-return mismatch** (domain knowledge) - Finance-specific logic\n",
    "\n",
    "---\n",
    "\n",
    "We'll compare our **learning version** (Z-score based) with the **production version** (Isolation Forest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "# IMPORTS\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "#\n",
    "# Standard imports for data analysis notebooks:\n",
    "#   - sys/pathlib: For path manipulation and project imports\n",
    "#   - datetime: For date handling\n",
    "#   - pandas: Data manipulation\n",
    "#   - numpy: Numerical operations\n",
    "#   - matplotlib/seaborn: Visualization\n",
    "#\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import date, timedelta\n",
    "\n",
    "# Add project root to Python path for imports\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Use a clean, professional style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Understanding Anomalies\n",
    "\n",
    "### Visual Intuition\n",
    "\n",
    "Before diving into algorithms, let's build intuition for what anomalies look like:\n",
    "\n",
    "1. **Unexplained Move**: A return that's way outside the normal distribution\n",
    "2. **Muted Response**: An event severity that doesn't match the return magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "# VISUAL EXPLANATION OF ANOMALY TYPES\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "#\n",
    "# LEFT PLOT - Unexplained Move:\n",
    "#   - Shows daily returns as a bar chart\n",
    "#   - Most returns cluster around 0 (normal)\n",
    "#   - One return at day 15 is a HUGE outlier (4 std devs!)\n",
    "#   - Red bars = outside 2 standard deviations\n",
    "#   - Question: Why did the market move so much? No event explains it!\n",
    "#\n",
    "# RIGHT PLOT - Muted Response:\n",
    "#   - Shows event severity (Goldstein scale) vs market returns\n",
    "#   - Day 3 has a MAJOR negative event (Goldstein = -8)\n",
    "#   - But the market barely moved (return ≈ 0.1%)\n",
    "#   - This is suspicious - major events should move markets!\n",
    "#\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# ─── LEFT: Unexplained Move ───\n",
    "np.random.seed(42)  # For reproducibility\n",
    "returns = np.random.normal(0, 1, 30)  # Normal returns\n",
    "returns[15] = 4  # Inject an outlier at day 15\n",
    "\n",
    "ax = axes[0]\n",
    "# Color bars based on whether they exceed 2 standard deviations\n",
    "colors = ['red' if abs(r) > 2 else 'steelblue' for r in returns]\n",
    "ax.bar(range(30), returns, color=colors, alpha=0.7)\n",
    "\n",
    "# Add threshold lines\n",
    "ax.axhline(y=2, color='red', linestyle='--', label='2 std devs (95% threshold)')\n",
    "ax.axhline(y=-2, color='red', linestyle='--')\n",
    "ax.axhline(y=0, color='black', linestyle='-')\n",
    "\n",
    "# Annotate the anomaly\n",
    "ax.annotate('UNEXPLAINED\\nMOVE!', xy=(15, 4), xytext=(20, 3.5),\n",
    "            arrowprops=dict(arrowstyle='->', color='red'),\n",
    "            fontsize=10, color='red', fontweight='bold')\n",
    "\n",
    "ax.set_xlabel('Day')\n",
    "ax.set_ylabel('Return (Z-score normalized)')\n",
    "ax.set_title('Unexplained Move\\n(Big return with no corresponding event)')\n",
    "ax.legend()\n",
    "\n",
    "# ─── RIGHT: Muted Response ───\n",
    "ax = axes[1]\n",
    "\n",
    "# Simulated data: Major negative event on day 3, but tiny market reaction\n",
    "days = range(7)\n",
    "event_severity = [0, 0, 0, -8, 0, 0, 0]  # Goldstein scale: -10 to +10\n",
    "market_returns = [0.5, -0.3, 0.2, 0.1, -0.4, 0.3, -0.2]  # Daily returns (%)\n",
    "\n",
    "x = np.arange(7)\n",
    "width = 0.35\n",
    "\n",
    "# Plot both series as grouped bars\n",
    "bars1 = ax.bar(x - width/2, event_severity, width, \n",
    "               label='Event Severity (Goldstein)', color='red', alpha=0.7)\n",
    "bars2 = ax.bar(x + width/2, [r * 10 for r in market_returns], width, \n",
    "               label='Market Return (scaled ×10)', color='green', alpha=0.7)\n",
    "\n",
    "ax.axhline(y=0, color='black', linestyle='-')\n",
    "\n",
    "# Annotate the mismatch\n",
    "ax.annotate('Major event\\nbut tiny\\nmarket move!', xy=(3, -8), xytext=(5, -6),\n",
    "            arrowprops=dict(arrowstyle='->', color='red'),\n",
    "            fontsize=10, color='red', fontweight='bold')\n",
    "\n",
    "ax.set_xlabel('Day')\n",
    "ax.set_ylabel('Magnitude')\n",
    "ax.set_title('Muted Response\\n(Big event but small market reaction)')\n",
    "ax.legend()\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([f'Day {i}' for i in x])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Insight:\")\n",
    "print(\"─\" * 50)\n",
    "print(\"• Unexplained Move: |return| > 2σ with no significant event\")\n",
    "print(\"• Muted Response: |event| > threshold but |return| < threshold\")\n",
    "print(\"\\nBoth suggest something unusual is happening!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 2. Learning Version: Z-Score Based Detection\n",
    "\n",
    "### The Z-Score Approach\n",
    "\n",
    "The simplest anomaly detection uses **Z-scores** (standard scores):\n",
    "\n",
    "$$Z = \\frac{X - \\mu}{\\sigma}$$\n",
    "\n",
    "Where:\n",
    "- X = observed value\n",
    "- μ = mean (from rolling window)\n",
    "- σ = standard deviation (from rolling window)\n",
    "\n",
    "**Interpretation:**\n",
    "- |Z| > 2 means the value is outside ~95% of normal observations\n",
    "- |Z| > 3 means the value is outside ~99.7% (extremely rare)\n",
    "\n",
    "### Why Use a Rolling Window?\n",
    "\n",
    "Markets change over time - volatility in 2020 was very different from 2019. Using a **rolling window** (e.g., last 30 days) adapts to current market conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "# LEARNING VERSION: AnomalyDetector\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "#\n",
    "# Our educational implementation uses three parameters:\n",
    "#\n",
    "# 1. zscore_threshold (default 2.0):\n",
    "#    - Returns with |Z| > threshold are flagged as anomalies\n",
    "#    - 2.0 = ~5% of data (1 in 20 days would be \"anomalous\" by chance)\n",
    "#    - 3.0 = ~0.3% of data (more conservative)\n",
    "#\n",
    "# 2. goldstein_threshold (default 5.0):\n",
    "#    - Events with |Goldstein| > threshold are considered \"significant\"\n",
    "#    - Goldstein scale: -10 (extreme conflict) to +10 (extreme cooperation)\n",
    "#    - |5| captures major events like conflicts, treaties, sanctions\n",
    "#\n",
    "# 3. lookback_days (default 30):\n",
    "#    - Rolling window for calculating mean and std\n",
    "#    - 30 days ≈ one trading month\n",
    "#    - Shorter = more responsive, noisier\n",
    "#    - Longer = more stable, slower to adapt\n",
    "#\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "from src.analysis.anomaly_detection import AnomalyDetector, explain_anomaly\n",
    "\n",
    "# Create detector with explicit parameters\n",
    "detector = AnomalyDetector(\n",
    "    zscore_threshold=2.0,      # Flag returns > 2 standard deviations\n",
    "    goldstein_threshold=5.0,   # Major events have |Goldstein| > 5\n",
    "    lookback_days=30,          # Use 30-day rolling window\n",
    ")\n",
    "\n",
    "print(\"Anomaly Detector Configuration\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"  Z-score threshold: {detector.zscore_threshold}\")\n",
    "print(f\"  Goldstein threshold: {detector.goldstein_threshold}\")\n",
    "print(f\"  Lookback window: {detector.lookback_days} days\")\n",
    "print()\n",
    "print(\"What this means:\")\n",
    "print(f\"  - 'Unexplained Move': Return where |Z| > {detector.zscore_threshold} but no event > {detector.goldstein_threshold}\")\n",
    "print(f\"  - 'Muted Response': Event |Goldstein| > {detector.goldstein_threshold} but |Z| < {detector.zscore_threshold}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "# DETECTING UNEXPLAINED MOVES\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "#\n",
    "# The detect_unexplained_moves() method:\n",
    "#   1. Fetches market data for the symbol and date range\n",
    "#   2. Calculates rolling Z-scores for each day's return\n",
    "#   3. For days where |Z| > threshold, checks if a significant event occurred\n",
    "#   4. Returns anomalies where the market moved but no event explains it\n",
    "#\n",
    "# These are interesting because they suggest:\n",
    "#   - Unreported news (insider information?)\n",
    "#   - Technical trading (momentum, stop-losses cascading)\n",
    "#   - Sentiment shift not captured by GDELT\n",
    "#\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "# Search last 60 days for anomalies\n",
    "end_date = date.today()\n",
    "start_date = end_date - timedelta(days=60)\n",
    "\n",
    "print(f\"Searching for unexplained moves in CL=F (Crude Oil)\")\n",
    "print(f\"Date range: {start_date} to {end_date}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "unexplained = detector.detect_unexplained_moves('CL=F', start_date, end_date)\n",
    "\n",
    "if unexplained:\n",
    "    print(f\"\\nFound {len(unexplained)} unexplained moves:\\n\")\n",
    "    print(f\"{'Date':<12} {'Return':>10} {'Z-score':>10} {'Interpretation'}\")\n",
    "    print(\"─\" * 60)\n",
    "    \n",
    "    for anomaly in unexplained[:5]:  # Show top 5\n",
    "        direction = '↑' if anomaly.actual_return > 0 else '↓'\n",
    "        severity = 'EXTREME' if abs(anomaly.z_score) > 3 else 'Notable'\n",
    "        print(f\"{anomaly.date}   {anomaly.actual_return*100:>+8.2f}%   {anomaly.z_score:>+8.2f}   {direction} {severity}\")\n",
    "else:\n",
    "    print(\"\\nNo unexplained moves detected.\")\n",
    "    print(\"This could mean:\")\n",
    "    print(\"  - All large moves had corresponding events (good!)\")\n",
    "    print(\"  - Insufficient data (check ingestion)\")\n",
    "    print(\"  - Market was calm during this period\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "# DETAILED ANOMALY EXPLANATION\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "#\n",
    "# The explain_anomaly() function provides a human-readable summary:\n",
    "#   - The date and return\n",
    "#   - The Z-score and what it means\n",
    "#   - What events (if any) occurred that day\n",
    "#   - Why it's classified as an anomaly\n",
    "#\n",
    "# This is useful for:\n",
    "#   - Portfolio managers investigating unusual P&L\n",
    "#   - Risk managers understanding exposure\n",
    "#   - Analysts researching market behavior\n",
    "#\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "if unexplained:\n",
    "    print(\"Detailed Explanation of First Anomaly\")\n",
    "    print(\"=\" * 50)\n",
    "    print(explain_anomaly(unexplained[0]))\n",
    "else:\n",
    "    print(\"No anomalies to explain.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## 3. Production Version: Isolation Forest\n",
    "\n",
    "### Why Machine Learning?\n",
    "\n",
    "Z-score detection has limitations:\n",
    "- Only looks at one feature (return magnitude)\n",
    "- Assumes normal distribution (returns have fat tails)\n",
    "- Can't capture complex patterns\n",
    "\n",
    "**Isolation Forest** is an unsupervised ML algorithm designed for anomaly detection:\n",
    "\n",
    "### How Isolation Forest Works\n",
    "\n",
    "1. **Random partitioning**: Randomly select a feature and split point\n",
    "2. **Recursive splitting**: Keep splitting until each point is isolated\n",
    "3. **Path length**: Count how many splits it took to isolate each point\n",
    "4. **Anomaly score**: Points isolated in FEWER splits are anomalies\n",
    "\n",
    "**Intuition**: Anomalies are \"few and different\" - they're easier to isolate from the crowd.\n",
    "\n",
    "### Key Parameter: Contamination\n",
    "\n",
    "The `contamination` parameter tells the algorithm what fraction of data is expected to be anomalous:\n",
    "- `0.05` = expect 5% of data to be anomalies\n",
    "- Lower = more conservative (fewer anomalies flagged)\n",
    "- Higher = more aggressive (more anomalies flagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "# PRODUCTION VERSION: Quick Analysis\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "#\n",
    "# The run_quick_anomaly_detection() function is a convenience wrapper:\n",
    "#   1. Creates a ProductionAnomalyDetector with default settings\n",
    "#   2. Runs all detection methods (Isolation Forest + Z-score + event mismatch)\n",
    "#   3. Returns a formatted summary report\n",
    "#\n",
    "# This is the \"just give me the answer\" approach for quick checks.\n",
    "#\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "from src.analysis.production_anomaly import ProductionAnomalyDetector, run_quick_anomaly_detection\n",
    "\n",
    "# Quick one-liner for rapid analysis\n",
    "report = run_quick_anomaly_detection('CL=F', days=60)\n",
    "\n",
    "if report:\n",
    "    print(\"Quick Anomaly Detection Report\")\n",
    "    print(\"=\" * 50)\n",
    "    print(report)\n",
    "else:\n",
    "    print(\"Insufficient data for anomaly detection.\")\n",
    "    print(\"Ensure the database is populated with market data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "# PRODUCTION VERSION: Full Analysis\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "#\n",
    "# For more control, instantiate ProductionAnomalyDetector directly.\n",
    "#\n",
    "# Key parameters:\n",
    "#   - contamination: Expected fraction of anomalies (default 0.05 = 5%)\n",
    "#   - zscore_threshold: For Z-score based detection (default 2.0)\n",
    "#   - random_state: For reproducibility\n",
    "#\n",
    "# The detect_all() method combines three detection approaches:\n",
    "#   1. Isolation Forest (ML-based, multivariate)\n",
    "#   2. Z-score (statistical, univariate)\n",
    "#   3. Event mismatch (domain-specific)\n",
    "#\n",
    "# Each anomaly is tagged with which method(s) detected it.\n",
    "#\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "prod_detector = ProductionAnomalyDetector(\n",
    "    contamination=0.05,    # Expect ~5% of data to be anomalous\n",
    "    zscore_threshold=2.0,  # Also flag Z-score outliers\n",
    ")\n",
    "\n",
    "# Run full detection\n",
    "anomalies = prod_detector.detect_all('CL=F', start_date, end_date)\n",
    "report = prod_detector.get_anomaly_report(anomalies, 'CL=F', start_date, end_date)\n",
    "\n",
    "print(\"Production Detector Results\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"  Total anomalies detected: {report.anomaly_count}\")\n",
    "print(f\"  Anomaly rate: {report.anomaly_rate*100:.1f}%\")\n",
    "print()\n",
    "print(\"Breakdown by type:\")\n",
    "print(f\"  Unexplained moves: {report.unexplained_moves}\")\n",
    "print(f\"  Muted responses: {report.muted_responses}\")\n",
    "print(f\"  Statistical outliers: {report.statistical_outliers}\")\n",
    "print()\n",
    "print(\"Interpretation:\")\n",
    "print(f\"  - {report.anomaly_rate*100:.1f}% of days were anomalous\")\n",
    "print(f\"  - {'Higher' if report.anomaly_rate > 0.05 else 'Lower'} than expected 5%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "# DETECTION METHOD BREAKDOWN\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "#\n",
    "# Each anomaly stores which detection method(s) flagged it:\n",
    "#   - 'isolation_forest': ML algorithm found it unusual\n",
    "#   - 'zscore': Statistical outlier (|Z| > threshold)\n",
    "#   - 'event_mismatch': Domain logic (event-return mismatch)\n",
    "#\n",
    "# Anomalies flagged by MULTIPLE methods are more reliable.\n",
    "#\n",
    "# The anomaly_probability field (0-1) indicates confidence:\n",
    "#   - Higher = more likely to be a true anomaly\n",
    "#   - Based on Isolation Forest's decision function\n",
    "#\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "if anomalies:\n",
    "    print(\"Anomaly Detection Methods\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"{'Date':<12} {'Type':<20} {'Return':>10} {'Prob':>8} {'Methods'}\")\n",
    "    print(\"─\" * 60)\n",
    "    \n",
    "    for a in anomalies[:10]:  # Show first 10\n",
    "        methods = ', '.join(a.detected_by)\n",
    "        print(f\"{a.date}   {a.anomaly_type:<20} {a.actual_return*100:>+8.2f}%   {a.anomaly_probability:>6.2f}   {methods}\")\n",
    "    \n",
    "    print(\"─\" * 60)\n",
    "    print(\"\\nNote: Anomalies flagged by multiple methods are more reliable.\")\n",
    "else:\n",
    "    print(\"No anomalies detected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## 4. Visualizing Anomalies\n",
    "\n",
    "Visualization is crucial for:\n",
    "- Validating that detections make sense\n",
    "- Communicating findings to stakeholders\n",
    "- Building intuition about market behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "# FETCH MARKET DATA FOR VISUALIZATION\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "#\n",
    "# We need the full time series to visualize anomalies in context.\n",
    "#\n",
    "# The visualization will show:\n",
    "#   - Price chart with anomaly points highlighted\n",
    "#   - Return chart with Z-score bands\n",
    "#\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "from src.db.queries import get_market_data\n",
    "from src.db.connection import get_session\n",
    "\n",
    "with get_session() as session:\n",
    "    data = get_market_data(session, 'CL=F', start_date, end_date)\n",
    "    \n",
    "    if data:\n",
    "        # Convert to DataFrame\n",
    "        market_df = pd.DataFrame([\n",
    "            {\n",
    "                'date': d.date,\n",
    "                'close': float(d.close),\n",
    "                'return': d.log_return,\n",
    "            }\n",
    "            for d in data\n",
    "        ]).dropna()\n",
    "        \n",
    "        # Calculate Z-scores using rolling window\n",
    "        # This matches what the detector does internally\n",
    "        market_df['z_score'] = (\n",
    "            (market_df['return'] - market_df['return'].rolling(30).mean()) /\n",
    "            market_df['return'].rolling(30).std()\n",
    "        )\n",
    "        \n",
    "        print(f\"Loaded {len(market_df)} days of data for CL=F\")\n",
    "        print(f\"Date range: {market_df['date'].min()} to {market_df['date'].max()}\")\n",
    "        print(f\"Price range: ${market_df['close'].min():.2f} - ${market_df['close'].max():.2f}\")\n",
    "    else:\n",
    "        print(\"No data available. Please run the ingestion scripts.\")\n",
    "        market_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "# PRICE AND RETURN CHART WITH ANOMALIES\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "#\n",
    "# TOP PANEL - Price Chart:\n",
    "#   - Shows the oil price over time\n",
    "#   - Red dots mark days that were flagged as anomalies\n",
    "#   - Helps you see: \"What happened to price on anomaly days?\"\n",
    "#\n",
    "# BOTTOM PANEL - Return Chart:\n",
    "#   - Bar chart of daily returns\n",
    "#   - Red bars = anomaly days\n",
    "#   - Dashed lines show ±2 standard deviation bands\n",
    "#   - Returns outside the bands are statistical outliers\n",
    "#\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "if market_df is not None and anomalies:\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(14, 10), sharex=True)\n",
    "    \n",
    "    # Get set of anomaly dates for quick lookup\n",
    "    anomaly_dates = set(a.date for a in anomalies)\n",
    "    \n",
    "    # ─── TOP: Price Chart ───\n",
    "    ax = axes[0]\n",
    "    ax.plot(market_df['date'], market_df['close'], linewidth=2, color='steelblue', label='Price')\n",
    "    \n",
    "    # Mark anomalies on price chart\n",
    "    for _, row in market_df.iterrows():\n",
    "        if row['date'] in anomaly_dates:\n",
    "            ax.scatter(row['date'], row['close'], color='red', s=100, zorder=5, label='_nolegend_')\n",
    "    \n",
    "    # Add a single legend entry for anomalies\n",
    "    ax.scatter([], [], color='red', s=100, label='Anomaly')\n",
    "    \n",
    "    ax.set_ylabel('Price ($)', fontsize=12)\n",
    "    ax.set_title('Oil (CL=F) Price with Anomalies Highlighted', fontsize=14)\n",
    "    ax.legend()\n",
    "    \n",
    "    # ─── BOTTOM: Return Chart ───\n",
    "    ax = axes[1]\n",
    "    \n",
    "    # Color bars by anomaly status\n",
    "    colors = ['red' if d in anomaly_dates else 'steelblue' for d in market_df['date']]\n",
    "    ax.bar(market_df['date'], market_df['return'] * 100, color=colors, alpha=0.7)\n",
    "    \n",
    "    # Add Z-score threshold lines (approximate using overall std)\n",
    "    std = market_df['return'].std() * 100\n",
    "    ax.axhline(y=2*std, color='red', linestyle='--', alpha=0.5, label='±2σ threshold')\n",
    "    ax.axhline(y=-2*std, color='red', linestyle='--', alpha=0.5)\n",
    "    ax.axhline(y=0, color='black', linestyle='-')\n",
    "    \n",
    "    ax.set_xlabel('Date', fontsize=12)\n",
    "    ax.set_ylabel('Daily Return (%)', fontsize=12)\n",
    "    ax.set_title('Daily Returns (Red Bars = Anomaly Detected)', fontsize=14)\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nChart Interpretation:\")\n",
    "    print(\"─\" * 50)\n",
    "    print(\"• Red dots/bars show days flagged as anomalies\")\n",
    "    print(\"• Returns outside dashed lines are >2σ from normal\")\n",
    "    print(\"• Look for clusters - multiple anomalies may indicate regime change\")\n",
    "else:\n",
    "    print(\"Insufficient data for visualization.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "# ANOMALY STATISTICS\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "#\n",
    "# LEFT PLOT - Probability Distribution:\n",
    "#   - Histogram of anomaly probabilities\n",
    "#   - Higher probability = more confident the point is anomalous\n",
    "#   - Skewed right = most anomalies are borderline\n",
    "#   - Uniform = detector is picking up genuine outliers\n",
    "#\n",
    "# RIGHT PLOT - Anomaly Types:\n",
    "#   - Pie chart showing breakdown by type\n",
    "#   - Helps understand WHAT kinds of anomalies are occurring\n",
    "#   - Useful for prioritizing investigation\n",
    "#\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "if anomalies:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # ─── LEFT: Probability Distribution ───\n",
    "    probs = [a.anomaly_probability for a in anomalies]\n",
    "    \n",
    "    axes[0].hist(probs, bins=20, edgecolor='black', alpha=0.7, color='red')\n",
    "    axes[0].axvline(x=np.mean(probs), color='blue', linestyle='--', \n",
    "                   label=f'Mean: {np.mean(probs):.2f}')\n",
    "    axes[0].set_xlabel('Anomaly Probability', fontsize=12)\n",
    "    axes[0].set_ylabel('Count', fontsize=12)\n",
    "    axes[0].set_title('Distribution of Anomaly Probabilities\\n(Higher = More Confident)', fontsize=12)\n",
    "    axes[0].legend()\n",
    "    \n",
    "    # ─── RIGHT: By Type ───\n",
    "    type_counts = {}\n",
    "    for a in anomalies:\n",
    "        type_counts[a.anomaly_type] = type_counts.get(a.anomaly_type, 0) + 1\n",
    "    \n",
    "    colors_pie = ['#ff6b6b', '#ffa502', '#ffd93d']  # Red, Orange, Yellow\n",
    "    axes[1].pie(\n",
    "        type_counts.values(),\n",
    "        labels=type_counts.keys(),\n",
    "        autopct='%1.1f%%',\n",
    "        colors=colors_pie[:len(type_counts)],\n",
    "        explode=[0.05] * len(type_counts),\n",
    "        shadow=True,\n",
    "    )\n",
    "    axes[1].set_title('Anomalies by Type', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nType Breakdown:\")\n",
    "    print(\"─\" * 40)\n",
    "    for atype, count in sorted(type_counts.items(), key=lambda x: -x[1]):\n",
    "        pct = count / len(anomalies) * 100\n",
    "        print(f\"  {atype}: {count} ({pct:.1f}%)\")\n",
    "else:\n",
    "    print(\"No anomalies to visualize.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## 5. Cross-Market Comparison\n",
    "\n",
    "Different markets have different anomaly patterns:\n",
    "- **Commodities** (oil, gold): Sensitive to geopolitical events\n",
    "- **Equities** (SPY): Broader economic factors\n",
    "- **VIX**: Inverse to market sentiment (spikes during fear)\n",
    "- **FX** (EURUSD): Policy and interest rate driven\n",
    "\n",
    "Comparing anomaly rates across markets can reveal:\n",
    "- Which markets are \"noisier\"\n",
    "- Whether events affect markets differently\n",
    "- Potential diversification opportunities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "# CROSS-MARKET ANOMALY COMPARISON\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "#\n",
    "# The compare_symbols() method:\n",
    "#   1. Runs anomaly detection on each symbol\n",
    "#   2. Returns a DataFrame with counts by type\n",
    "#   3. Enables direct comparison across markets\n",
    "#\n",
    "# Symbols analyzed:\n",
    "#   - CL=F: Crude Oil Futures\n",
    "#   - GC=F: Gold Futures (safe haven)\n",
    "#   - SPY: S&P 500 ETF (broad US equities)\n",
    "#   - ^VIX: Volatility Index (fear gauge)\n",
    "#   - EURUSD=X: Euro/USD exchange rate\n",
    "#\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "symbols = ['CL=F', 'GC=F', 'SPY', '^VIX', 'EURUSD=X']\n",
    "\n",
    "print(f\"Comparing anomaly rates across {len(symbols)} markets\")\n",
    "print(f\"Date range: {start_date} to {end_date}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "comparison = prod_detector.compare_symbols(symbols, start_date, end_date)\n",
    "\n",
    "if not comparison.empty:\n",
    "    print(\"\\nAnomaly Comparison Across Markets\")\n",
    "    print(\"─\" * 60)\n",
    "    display(comparison)\n",
    "else:\n",
    "    print(\"Insufficient data for comparison.\")\n",
    "    print(\"Ensure data is ingested for all symbols.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "# VISUALIZATION: GROUPED BAR CHART\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "#\n",
    "# This chart shows anomaly counts by type for each market.\n",
    "#\n",
    "# Visual encoding:\n",
    "#   - X-axis: Different markets\n",
    "#   - Y-axis: Number of anomalies\n",
    "#   - Colors: Different anomaly types\n",
    "#\n",
    "# What to look for:\n",
    "#   - Which markets have the most anomalies?\n",
    "#   - Which types dominate for each market?\n",
    "#   - Are there patterns (e.g., VIX has more unexplained moves)?\n",
    "#\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "if not comparison.empty:\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    x = np.arange(len(comparison))\n",
    "    width = 0.25\n",
    "    \n",
    "    # Create grouped bars\n",
    "    bars1 = ax.bar(x - width, comparison['unexplained_moves'], width, \n",
    "                   label='Unexplained Moves', color='#ff6b6b', alpha=0.8)\n",
    "    bars2 = ax.bar(x, comparison['muted_responses'], width, \n",
    "                   label='Muted Responses', color='#ffa502', alpha=0.8)\n",
    "    bars3 = ax.bar(x + width, comparison['statistical_outliers'], width, \n",
    "                   label='Statistical Outliers', color='#ffd93d', alpha=0.8)\n",
    "    \n",
    "    ax.set_xlabel('Symbol', fontsize=12)\n",
    "    ax.set_ylabel('Count', fontsize=12)\n",
    "    ax.set_title('Anomaly Types by Market', fontsize=14)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(comparison['symbol'])\n",
    "    ax.legend()\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bars in [bars1, bars2, bars3]:\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            if height > 0:\n",
    "                ax.annotate(f'{int(height)}',\n",
    "                           xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                           ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nInsights:\")\n",
    "    print(\"─\" * 50)\n",
    "    most_anomalies = comparison.loc[comparison['anomaly_count'].idxmax()]\n",
    "    least_anomalies = comparison.loc[comparison['anomaly_count'].idxmin()]\n",
    "    print(f\"• Most anomalous market: {most_anomalies['symbol']} ({most_anomalies['anomaly_count']} anomalies)\")\n",
    "    print(f\"• Least anomalous market: {least_anomalies['symbol']} ({least_anomalies['anomaly_count']} anomalies)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## 6. How Isolation Forest Works\n",
    "\n",
    "Let's visualize the Isolation Forest algorithm to build intuition.\n",
    "\n",
    "### The Key Insight\n",
    "\n",
    "**Anomalies are \"few and different\"** - they're easier to isolate from the crowd.\n",
    "\n",
    "Imagine a crowd of people standing together, with a few standing far away:\n",
    "- Normal points: Need many random cuts to isolate each person\n",
    "- Anomalies: Just a few cuts separates the loners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "# ISOLATION FOREST VISUALIZATION\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "#\n",
    "# We create synthetic data to demonstrate how Isolation Forest works:\n",
    "#   - 100 normal points clustered around the origin\n",
    "#   - 3 anomaly points far from the cluster\n",
    "#\n",
    "# LEFT PLOT - Predictions:\n",
    "#   - Blue points = normal (inliers)\n",
    "#   - Red points = anomalies (outliers)\n",
    "#   - The algorithm correctly identifies the distant points\n",
    "#\n",
    "# RIGHT PLOT - Anomaly Scores:\n",
    "#   - Colormap shows the decision function\n",
    "#   - Lower scores (red) = more anomalous\n",
    "#   - Higher scores (green) = more normal\n",
    "#\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "\n",
    "# Normal data: cluster around origin\n",
    "normal_data = np.random.randn(100, 2)\n",
    "\n",
    "# Anomalies: far from the cluster\n",
    "anomalies_data = np.array([\n",
    "    [4, 4],    # Top-right corner\n",
    "    [-4, -4],  # Bottom-left corner  \n",
    "    [4, -4]    # Bottom-right corner\n",
    "])\n",
    "\n",
    "# Combine\n",
    "data = np.vstack([normal_data, anomalies_data])\n",
    "\n",
    "# Fit Isolation Forest\n",
    "iso_forest = IsolationForest(\n",
    "    contamination=0.03,  # Expect ~3% anomalies (3 out of 103)\n",
    "    random_state=42\n",
    ")\n",
    "predictions = iso_forest.fit_predict(data)\n",
    "scores = iso_forest.decision_function(data)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# ─── LEFT: Predictions ───\n",
    "ax = axes[0]\n",
    "colors = ['red' if p == -1 else 'steelblue' for p in predictions]\n",
    "ax.scatter(data[:, 0], data[:, 1], c=colors, alpha=0.6, s=50)\n",
    "\n",
    "# Label the groups\n",
    "ax.scatter([], [], c='steelblue', label='Normal (predicted)', s=50)\n",
    "ax.scatter([], [], c='red', label='Anomaly (predicted)', s=50)\n",
    "\n",
    "ax.set_xlabel('Feature 1')\n",
    "ax.set_ylabel('Feature 2')\n",
    "ax.set_title('Isolation Forest: Predictions\\n(Red = Detected as Anomaly)')\n",
    "ax.legend()\n",
    "ax.set_xlim(-6, 6)\n",
    "ax.set_ylim(-6, 6)\n",
    "\n",
    "# ─── RIGHT: Decision Function (Anomaly Scores) ───\n",
    "ax = axes[1]\n",
    "scatter = ax.scatter(data[:, 0], data[:, 1], c=scores, cmap='RdYlGn', alpha=0.6, s=50)\n",
    "plt.colorbar(scatter, ax=ax, label='Anomaly Score\\n(lower = more anomalous)')\n",
    "\n",
    "ax.set_xlabel('Feature 1')\n",
    "ax.set_ylabel('Feature 2')\n",
    "ax.set_title('Isolation Forest: Anomaly Scores\\n(Red = Low Score = Anomalous)')\n",
    "ax.set_xlim(-6, 6)\n",
    "ax.set_ylim(-6, 6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Explain the algorithm\n",
    "print(\"\\nHow Isolation Forest Works:\")\n",
    "print(\"═\" * 60)\n",
    "print(\"\")\n",
    "print(\"1. RANDOM PARTITIONING:\")\n",
    "print(\"   → Randomly select a feature (e.g., Feature 1)\")\n",
    "print(\"   → Randomly select a split point (e.g., x = 2.5)\")\n",
    "print(\"   → Split data into left and right partitions\")\n",
    "print(\"\")\n",
    "print(\"2. RECURSIVE SPLITTING:\")\n",
    "print(\"   → Keep splitting until each point is isolated\")\n",
    "print(\"   → This creates a 'path' for each point\")\n",
    "print(\"\")\n",
    "print(\"3. PATH LENGTH = ANOMALY SCORE:\")\n",
    "print(\"   → Anomalies are isolated in FEWER splits (short path)\")\n",
    "print(\"   → Normal points need MORE splits (long path)\")\n",
    "print(\"\")\n",
    "print(\"4. INTUITION:\")\n",
    "print(\"   → Anomalies are 'few and different'\")\n",
    "print(\"   → They stand out, so random cuts find them quickly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Anomaly Detection** finds unusual market-event patterns that warrant investigation.\n",
    "\n",
    "---\n",
    "\n",
    "### Anomaly Types\n",
    "\n",
    "| Type | Definition | Possible Cause | Action |\n",
    "|------|------------|----------------|--------|\n",
    "| **Unexplained Move** | Large return, no event | Unreported news, technical trading | Investigate news sources |\n",
    "| **Muted Response** | Large event, small return | Already priced in, market skepticism | Review positioning |\n",
    "| **Statistical Outlier** | Detected by ML | General unusual behavior | Monitor closely |\n",
    "\n",
    "---\n",
    "\n",
    "### Detection Methods\n",
    "\n",
    "| Method | Pros | Cons |\n",
    "|--------|------|------|\n",
    "| **Z-score** | Simple, interpretable | Assumes normality, univariate |\n",
    "| **Isolation Forest** | Handles multivariate, robust | Black box, needs tuning |\n",
    "| **Event Mismatch** | Domain-specific, meaningful | Requires event data |\n",
    "\n",
    "---\n",
    "\n",
    "### Two Implementations\n",
    "\n",
    "| Version | Class | Use Case |\n",
    "|---------|-------|----------|\n",
    "| **Learning** | `AnomalyDetector` | Understand Z-scores, interviews |\n",
    "| **Production** | `ProductionAnomalyDetector` | Real work, combines methods |\n",
    "\n",
    "---\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Anomalies are rare by definition** - don't expect many\n",
    "2. **Multiple methods > single method** - combine for robustness\n",
    "3. **Context matters** - always investigate before acting\n",
    "4. **Tune contamination carefully** - too high = false positives\n",
    "\n",
    "---\n",
    "\n",
    "**Next:** See `04_classification_demo.ipynb` to predict market direction from events."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
